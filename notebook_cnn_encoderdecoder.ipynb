{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "qmkj-80IHxnd"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_xnMOsbqHz61"
   },
   "source": [
    "# CNN (Convolutional) EncoderDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements = \"\"\"\n",
    "# keras\n",
    "# git+https://www.github.com/keras-team/keras-contrib.git\n",
    "# matplotlib\n",
    "# numpy\n",
    "# scipy\n",
    "# pillow\n",
    "# #urllib\n",
    "# #skimage\n",
    "# scikit-image\n",
    "# #gzip\n",
    "# #pickle\n",
    "# \"\"\"\n",
    "# %store requirements > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1_Y75QXJS6h"
   },
   "source": [
    "## Import TensorFlow and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfIk2es3hJEd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# !pip install tensorflow-gpu==2.0.0-alpha0\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from random import shuffle\n",
    "import PIL\n",
    "import json\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "# matplotlib.use('TKAgg')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "## Load the dataset\n",
    "\n",
    "Steps to generate URL used below:\n",
    "- Say, your data files are in the directory called 'input'\n",
    "- Manually create a zip file, 'input.zip'\n",
    "- Sync it to gDrive\n",
    "- In gDrive, Share it with Public model, copy its share-able link\n",
    "- Use https://sites.google.com/site/gdocs2direct/ to generate corresponding Direct link\n",
    "- Paste it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Continuum\\\\anaconda3\\\\envs\\\\odsc_ws\\\\notebooks\\\\MidcurveNN-master'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# working directory\n",
    "wdir = os.getcwd()\n",
    "wdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "height": 68
    },
    "colab_type": "code",
    "id": "Kn-k8kTXuAlv",
    "outputId": "cd1649cb-4f17-4857-a137-e7b1a5e1d002"
   },
   "outputs": [],
   "source": [
    "# _URL = 'https://drive.google.com/uc?export=download&id=16rqDFLO__WySSQGlAht0FEj2uJZg4M9M'\n",
    "\n",
    "# path_to_zip = tf.keras.utils.get_file('input.zip',\n",
    "#                                       origin=_URL,\n",
    "#                                       extract=True)\n",
    "\n",
    "# input_data_folder = os.path.join(os.path.dirname(path_to_zip), 'input')\n",
    "input_data_folder = wdir + \"\\data\\input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input_image_pairs(datafolder=input_data_folder):\n",
    "    profile_pngs = []\n",
    "    midcurve_pngs = []\n",
    "    for file in os.listdir(datafolder):\n",
    "        fullpath = os.path.join(datafolder, file)\n",
    "        if os.path.isdir(fullpath):\n",
    "            continue\n",
    "        if file.endswith(\".png\"):\n",
    "            if file.find(\"Profile\") != -1:\n",
    "                profile_pngs.append(fullpath)\n",
    "            if file.find(\"Midcurve\") != -1:\n",
    "                midcurve_pngs.append(fullpath)\n",
    "    profile_pngs = sorted(profile_pngs)\n",
    "    midcurve_pngs = sorted(midcurve_pngs)\n",
    "    return profile_pngs,midcurve_pngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CbTEt448b4R"
   },
   "outputs": [],
   "source": [
    "def get_training_data(datafolder = input_data_folder):\n",
    "    profile_pngs,midcurve_pngs = read_input_image_pairs(datafolder)\n",
    "    \n",
    "    profile_pngs_objs = [img_to_array(load_img(f, color_mode='rgba', target_size=(100, 100))) for f in profile_pngs ]\n",
    "    midcurve_pngs_objs = [img_to_array(load_img(f, color_mode='rgba', target_size=(100, 100))) for f in midcurve_pngs]\n",
    "\n",
    "#     profile_pngs_objs = np.array([x.reshape((1,) + x.shape) for x in profile_pngs_objs])\n",
    "#     midcurve_pngs_objs = np.array([x.reshape((1,) + x.shape) for x in midcurve_pngs_objs])\n",
    "\n",
    "    profile_pngs_gray_objs = [x[:,:,3] for x in profile_pngs_objs]\n",
    "    midcurve_pngs_gray_objs =[x[:,:,3] for x in midcurve_pngs_objs]\n",
    "    \n",
    "#     profile_pngs_gray_objs = [np.where(x>128, 0, 1) for x in profile_pngs_gray_objs]\n",
    "#     midcurve_pngs_gray_objs =[np.where(x>128, 0, 1) for x in midcurve_pngs_gray_objs]\n",
    "        \n",
    "    # shufle them\n",
    "    zipped_profiles_midcurves = [(p,m) for p,m in zip(profile_pngs_gray_objs,midcurve_pngs_gray_objs)]\n",
    "    shuffle(zipped_profiles_midcurves)\n",
    "    profile_pngs_gray_objs, midcurve_pngs_gray_objs = zip(*zipped_profiles_midcurves)\n",
    "    \n",
    "    return profile_pngs_gray_objs, midcurve_pngs_gray_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "height": 558
    },
    "colab_type": "code",
    "id": "4OLHMpsQ5aOv",
    "outputId": "5bfde74b-a0dd-42fa-8e9c-4f6eb42215ed"
   },
   "outputs": [],
   "source": [
    "profile_pngs_objs, midcurve_pngs_objs = get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(original_imgs,computed_imgs):\n",
    "    n = 10  # how many digits we will display\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(original_imgs[i].reshape(100, 100),cmap='gray_r')\n",
    "#         plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(computed_imgs[i].reshape(100, 100),cmap='gray_r')\n",
    "#         plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(profile_pngs_objs,midcurve_pngs_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "def build_cnn_autoencoder_model(profile_pngs_gray_objs, midcurve_pngs_gray_objs,encoding_dim = 100, input_dim = 100):\n",
    "    input_img = Input(shape=(input_dim, input_dim, 1))  # adapt this if using `channels_first` image data format\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    # at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "    \n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    \n",
    "    # Model 1: Full AutoEncoder, includes both encoder single dense layer and decoder single dense layer. \n",
    "    # This model maps an input to its reconstruction\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    \n",
    "    # Compilation of Autoencoder (only)\n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    \n",
    "    \n",
    "    # Training\n",
    "    profile_pngs_flat_objs = [x.reshape(input_dim,input_dim,1) for x in profile_pngs_gray_objs]\n",
    "    midcurve_pngs_flat_objs = [x.reshape(input_dim,input_dim,1) for x in midcurve_pngs_gray_objs]\n",
    "    \n",
    "    profile_pngs_objs = np.array(profile_pngs_flat_objs)\n",
    "    midcurve_pngs_objs= np.array(midcurve_pngs_flat_objs)\n",
    "    \n",
    "    train_size = int(len(profile_pngs_objs)*0.7)\n",
    "    x_train = profile_pngs_objs[:train_size]\n",
    "    y_train = midcurve_pngs_objs[:train_size]\n",
    "    x_test = profile_pngs_objs[train_size:]\n",
    "    y_test = midcurve_pngs_objs[train_size:]\n",
    "    autoencoder.fit(x_train, y_train,\n",
    "                epochs=200,\n",
    "                batch_size=5,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, y_test))\n",
    "        \n",
    "    encoded_imgs = autoencoder.predict(x_test)\n",
    "    decoded_imgs = autoencoder.predict(encoded_imgs)    \n",
    "        \n",
    "    return x_test,decoded_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 313 samples, validate on 135 samples\n",
      "Epoch 1/200\n",
      "313/313 [==============================] - 18s 59ms/step - loss: -15.8818 - val_loss: -18.0763\n",
      "Epoch 2/200\n",
      "313/313 [==============================] - 9s 28ms/step - loss: -17.2642 - val_loss: -18.2322\n",
      "Epoch 3/200\n",
      "313/313 [==============================] - 9s 28ms/step - loss: -17.4052 - val_loss: -18.3614\n",
      "Epoch 4/200\n",
      "313/313 [==============================] - 9s 28ms/step - loss: -17.4753 - val_loss: -18.2055\n",
      "Epoch 5/200\n",
      "313/313 [==============================] - 9s 29ms/step - loss: -17.5115 - val_loss: -18.4261\n",
      "Epoch 6/200\n",
      "313/313 [==============================] - 9s 29ms/step - loss: -17.5336 - val_loss: -18.4744\n",
      "Epoch 7/200\n",
      "313/313 [==============================] - 9s 27ms/step - loss: -17.5651 - val_loss: -18.4733\n",
      "Epoch 8/200\n",
      "313/313 [==============================] - 9s 28ms/step - loss: -17.6106 - val_loss: -18.4747\n",
      "Epoch 9/200\n",
      "313/313 [==============================] - 9s 28ms/step - loss: -17.6189 - val_loss: -18.5265\n",
      "Epoch 10/200\n",
      "313/313 [==============================] - 9s 28ms/step - loss: -17.6348 - val_loss: -18.5286\n",
      "Epoch 11/200\n",
      "313/313 [==============================] - 8s 27ms/step - loss: -17.6410 - val_loss: -18.5598\n",
      "Epoch 12/200\n",
      "313/313 [==============================] - 9s 27ms/step - loss: -17.6588 - val_loss: -18.5373\n",
      "Epoch 13/200\n",
      "313/313 [==============================] - 9s 28ms/step - loss: -17.6734 - val_loss: -18.5797\n",
      "Epoch 14/200\n",
      "313/313 [==============================] - 8s 27ms/step - loss: -17.6858 - val_loss: -18.5760\n",
      "Epoch 15/200\n",
      "313/313 [==============================] - 9s 27ms/step - loss: -17.6862 - val_loss: -18.5913\n",
      "Epoch 16/200\n",
      "313/313 [==============================] - 8s 27ms/step - loss: -17.7043 - val_loss: -18.6147\n",
      "Epoch 17/200\n",
      "313/313 [==============================] - 8s 26ms/step - loss: -17.7127 - val_loss: -18.5964\n",
      "Epoch 18/200\n",
      "313/313 [==============================] - 9s 28ms/step - loss: -17.7273 - val_loss: -18.6274\n",
      "Epoch 19/200\n",
      "313/313 [==============================] - 8s 27ms/step - loss: -17.7291 - val_loss: -18.3950\n",
      "Epoch 20/200\n",
      "313/313 [==============================] - 9s 27ms/step - loss: -17.7249 - val_loss: -18.6113\n",
      "Epoch 21/200\n",
      "313/313 [==============================] - 8s 27ms/step - loss: -17.7084 - val_loss: -18.6277\n",
      "Epoch 22/200\n",
      "313/313 [==============================] - 8s 27ms/step - loss: -17.7525 - val_loss: -18.5420\n",
      "Epoch 23/200\n",
      "313/313 [==============================] - 8s 27ms/step - loss: -17.7494 - val_loss: -18.0209\n",
      "Epoch 24/200\n",
      "313/313 [==============================] - 8s 27ms/step - loss: -17.7492 - val_loss: -18.2922\n",
      "Epoch 25/200\n",
      "313/313 [==============================] - 8s 25ms/step - loss: -17.7320 - val_loss: -18.4585\n",
      "Epoch 26/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.7454 - val_loss: -18.6440\n",
      "Epoch 27/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7493 - val_loss: -18.5860\n",
      "Epoch 28/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7598 - val_loss: -18.6801\n",
      "Epoch 29/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.7566 - val_loss: -18.4699\n",
      "Epoch 30/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.7657 - val_loss: -18.6218\n",
      "Epoch 31/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.7488 - val_loss: -18.6534\n",
      "Epoch 32/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7598 - val_loss: -18.6790\n",
      "Epoch 33/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7682 - val_loss: -18.6676\n",
      "Epoch 34/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7695 - val_loss: -18.6252\n",
      "Epoch 35/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7797 - val_loss: -18.2869\n",
      "Epoch 36/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7627 - val_loss: -18.4334\n",
      "Epoch 37/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7735 - val_loss: -18.3849\n",
      "Epoch 38/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7298 - val_loss: -18.4189\n",
      "Epoch 39/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7946 - val_loss: -18.5270\n",
      "Epoch 40/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7618 - val_loss: -18.5500\n",
      "Epoch 41/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7932 - val_loss: -18.6164\n",
      "Epoch 42/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7873 - val_loss: -18.6654\n",
      "Epoch 43/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7929 - val_loss: -18.6368\n",
      "Epoch 44/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7763 - val_loss: -18.6802\n",
      "Epoch 45/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7891 - val_loss: -18.6222\n",
      "Epoch 46/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7928 - val_loss: -18.7113\n",
      "Epoch 47/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7954 - val_loss: -18.6961\n",
      "Epoch 48/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7949 - val_loss: -18.6745\n",
      "Epoch 49/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.7772 - val_loss: -18.7099\n",
      "Epoch 50/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7802 - val_loss: -18.7050\n",
      "Epoch 51/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.8041 - val_loss: -18.6978\n",
      "Epoch 52/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7963 - val_loss: -18.7092\n",
      "Epoch 53/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.8097 - val_loss: -18.4838\n",
      "Epoch 54/200\n",
      "313/313 [==============================] - 4s 11ms/step - loss: -17.7910 - val_loss: -18.5149\n",
      "Epoch 55/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.7808 - val_loss: -18.4086\n",
      "Epoch 56/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7903 - val_loss: -18.6814\n",
      "Epoch 57/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7868 - val_loss: -18.6994\n",
      "Epoch 58/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.8126 - val_loss: -18.6787\n",
      "Epoch 59/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7764 - val_loss: -18.7068\n",
      "Epoch 60/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.8056 - val_loss: -18.6472\n",
      "Epoch 61/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7905 - val_loss: -18.1418\n",
      "Epoch 62/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.7792 - val_loss: -18.7275\n",
      "Epoch 63/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.8134 - val_loss: -18.6962\n",
      "Epoch 64/200\n",
      "313/313 [==============================] - 4s 14ms/step - loss: -17.7972 - val_loss: -18.7072\n",
      "Epoch 65/200\n",
      "313/313 [==============================] - 5s 17ms/step - loss: -17.8113 - val_loss: -18.4951\n",
      "Epoch 66/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.7698 - val_loss: -18.5625\n",
      "Epoch 67/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.8067 - val_loss: -18.6303\n",
      "Epoch 68/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.8050 - val_loss: -18.6035\n",
      "Epoch 69/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.8015 - val_loss: -18.7013\n",
      "Epoch 70/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.8179 - val_loss: -18.6257\n",
      "Epoch 71/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7943 - val_loss: -18.7202\n",
      "Epoch 72/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.8032 - val_loss: -18.7237\n",
      "Epoch 73/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.8162 - val_loss: -18.6641\n",
      "Epoch 74/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.8086 - val_loss: -18.6919\n",
      "Epoch 75/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7854 - val_loss: -18.7016\n",
      "Epoch 76/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.8057 - val_loss: -18.5542\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: -17.8086 - val_loss: -18.6928\n",
      "Epoch 78/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.8116 - val_loss: -18.7048\n",
      "Epoch 79/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.8195 - val_loss: -18.6962\n",
      "Epoch 80/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.8070 - val_loss: -18.6877\n",
      "Epoch 81/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7822 - val_loss: -18.6158\n",
      "Epoch 82/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.8070 - val_loss: -18.7073\n",
      "Epoch 83/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7835 - val_loss: -18.6628\n",
      "Epoch 84/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.8027 - val_loss: -18.6570\n",
      "Epoch 85/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.8093 - val_loss: -18.7166\n",
      "Epoch 86/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.8212 - val_loss: -18.3697\n",
      "Epoch 87/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7327 - val_loss: -18.5809\n",
      "Epoch 88/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.8225 - val_loss: -18.7040\n",
      "Epoch 89/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.8007 - val_loss: -18.7106\n",
      "Epoch 90/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.8086 - val_loss: -18.7092\n",
      "Epoch 91/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.8029 - val_loss: -18.7163\n",
      "Epoch 92/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.7932 - val_loss: -18.1242\n",
      "Epoch 93/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.8139 - val_loss: -18.6128\n",
      "Epoch 94/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.7726 - val_loss: -18.7038\n",
      "Epoch 95/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7815 - val_loss: -18.6899\n",
      "Epoch 96/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.8059 - val_loss: -18.6939\n",
      "Epoch 97/200\n",
      "313/313 [==============================] - 4s 13ms/step - loss: -17.7998 - val_loss: -18.7178\n",
      "Epoch 98/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.8219 - val_loss: -18.7085\n",
      "Epoch 99/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.7969 - val_loss: -18.6691\n",
      "Epoch 100/200\n",
      "313/313 [==============================] - 4s 14ms/step - loss: -17.8100 - val_loss: -18.7197\n",
      "Epoch 101/200\n",
      "313/313 [==============================] - 4s 13ms/step - loss: -17.7528 - val_loss: -18.6900\n",
      "Epoch 102/200\n",
      "313/313 [==============================] - 5s 16ms/step - loss: -17.8017 - val_loss: -18.6911\n",
      "Epoch 103/200\n",
      "313/313 [==============================] - 5s 14ms/step - loss: -17.8087 - val_loss: -18.6948\n",
      "Epoch 104/200\n",
      "313/313 [==============================] - 4s 13ms/step - loss: -17.8173 - val_loss: -18.7185\n",
      "Epoch 105/200\n",
      "313/313 [==============================] - 5s 14ms/step - loss: -17.8026 - val_loss: -18.6077\n",
      "Epoch 106/200\n",
      "313/313 [==============================] - 5s 16ms/step - loss: -17.7777 - val_loss: -18.7125\n",
      "Epoch 107/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.7936 - val_loss: -18.7132\n",
      "Epoch 108/200\n",
      "313/313 [==============================] - 5s 15ms/step - loss: -17.8288 - val_loss: -18.7210\n",
      "Epoch 109/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.7947 - val_loss: -18.7120\n",
      "Epoch 110/200\n",
      "313/313 [==============================] - 4s 13ms/step - loss: -17.8045 - val_loss: -18.7019\n",
      "Epoch 111/200\n",
      "313/313 [==============================] - 4s 13ms/step - loss: -17.8145 - val_loss: -18.6968\n",
      "Epoch 112/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.7893 - val_loss: -18.6592\n",
      "Epoch 113/200\n",
      "313/313 [==============================] - 5s 14ms/step - loss: -17.7698 - val_loss: -18.4454\n",
      "Epoch 114/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.7711 - val_loss: -18.7270\n",
      "Epoch 115/200\n",
      "313/313 [==============================] - 4s 13ms/step - loss: -17.7509 - val_loss: -18.7343\n",
      "Epoch 116/200\n",
      "313/313 [==============================] - 4s 13ms/step - loss: -17.7987 - val_loss: -18.6672\n",
      "Epoch 117/200\n",
      "313/313 [==============================] - 4s 14ms/step - loss: -17.7569 - val_loss: -18.4136\n",
      "Epoch 118/200\n",
      "313/313 [==============================] - 4s 11ms/step - loss: -17.7685 - val_loss: -18.7022\n",
      "Epoch 119/200\n",
      "313/313 [==============================] - 4s 14ms/step - loss: -17.8012 - val_loss: -18.6442\n",
      "Epoch 120/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.7894 - val_loss: -18.7027\n",
      "Epoch 121/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.7814 - val_loss: -18.6420\n",
      "Epoch 122/200\n",
      "313/313 [==============================] - 4s 13ms/step - loss: -17.7968 - val_loss: -18.6897\n",
      "Epoch 123/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.8002 - val_loss: -18.6700\n",
      "Epoch 124/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7549 - val_loss: -18.6602\n",
      "Epoch 125/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.7761 - val_loss: -18.7283\n",
      "Epoch 126/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.7993 - val_loss: -18.7385\n",
      "Epoch 127/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.7960 - val_loss: -18.7108\n",
      "Epoch 128/200\n",
      "313/313 [==============================] - 4s 13ms/step - loss: -17.7735 - val_loss: -18.7223\n",
      "Epoch 129/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.7848 - val_loss: -18.7154\n",
      "Epoch 130/200\n",
      "313/313 [==============================] - 4s 14ms/step - loss: -17.7961 - val_loss: -18.7344\n",
      "Epoch 131/200\n",
      "313/313 [==============================] - 5s 17ms/step - loss: -17.8013 - val_loss: -18.5465\n",
      "Epoch 132/200\n",
      "313/313 [==============================] - 4s 11ms/step - loss: -17.7718 - val_loss: -18.7173\n",
      "Epoch 133/200\n",
      "313/313 [==============================] - 4s 14ms/step - loss: -17.7899 - val_loss: -18.7127\n",
      "Epoch 134/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.7834 - val_loss: -18.7242\n",
      "Epoch 135/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.8168 - val_loss: -18.7254\n",
      "Epoch 136/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.7894 - val_loss: -18.5619\n",
      "Epoch 137/200\n",
      "313/313 [==============================] - 4s 14ms/step - loss: -17.7527 - val_loss: -18.6401\n",
      "Epoch 138/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.7615 - val_loss: -18.7164\n",
      "Epoch 139/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7821 - val_loss: -18.6941\n",
      "Epoch 140/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.7801 - val_loss: -18.6361\n",
      "Epoch 141/200\n",
      "313/313 [==============================] - 4s 14ms/step - loss: -17.7907 - val_loss: -18.7131\n",
      "Epoch 142/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.7560 - val_loss: -18.6159\n",
      "Epoch 143/200\n",
      "313/313 [==============================] - 4s 13ms/step - loss: -17.7679 - val_loss: -18.6987\n",
      "Epoch 144/200\n",
      "313/313 [==============================] - 4s 13ms/step - loss: -17.7463 - val_loss: -18.6876\n",
      "Epoch 145/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.7914 - val_loss: -18.5795\n",
      "Epoch 146/200\n",
      "313/313 [==============================] - 4s 13ms/step - loss: -17.8002 - val_loss: -18.7260\n",
      "Epoch 147/200\n",
      "313/313 [==============================] - 4s 14ms/step - loss: -17.7799 - val_loss: -18.7418\n",
      "Epoch 148/200\n",
      "313/313 [==============================] - 4s 13ms/step - loss: -17.7982 - val_loss: -18.7109\n",
      "Epoch 149/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.7750 - val_loss: -18.7263\n",
      "Epoch 150/200\n",
      "313/313 [==============================] - 4s 14ms/step - loss: -17.8069 - val_loss: -18.6359\n",
      "Epoch 151/200\n",
      "313/313 [==============================] - 4s 13ms/step - loss: -17.7549 - val_loss: -18.6986\n",
      "Epoch 152/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7753 - val_loss: -18.6214\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7738 - val_loss: -18.6811\n",
      "Epoch 154/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7254 - val_loss: -16.4488\n",
      "Epoch 155/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7357 - val_loss: -18.7062\n",
      "Epoch 156/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7300 - val_loss: -18.6852\n",
      "Epoch 157/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7838 - val_loss: -18.2119\n",
      "Epoch 158/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7719 - val_loss: -18.6689\n",
      "Epoch 159/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.7467 - val_loss: -18.7090\n",
      "Epoch 160/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7811 - val_loss: -18.5846\n",
      "Epoch 161/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7803 - val_loss: -18.7168\n",
      "Epoch 162/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.7947 - val_loss: -18.7153\n",
      "Epoch 163/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7510 - val_loss: -18.7134\n",
      "Epoch 164/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7919 - val_loss: -18.6438\n",
      "Epoch 165/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7711 - val_loss: -18.6935\n",
      "Epoch 166/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7304 - val_loss: -18.7123\n",
      "Epoch 167/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.6888 - val_loss: -18.6908\n",
      "Epoch 168/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7724 - val_loss: -18.6657\n",
      "Epoch 169/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7564 - val_loss: -18.7070\n",
      "Epoch 170/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7560 - val_loss: -18.6938\n",
      "Epoch 171/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7291 - val_loss: -18.6800\n",
      "Epoch 172/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7813 - val_loss: -18.7068\n",
      "Epoch 173/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7810 - val_loss: -18.7079\n",
      "Epoch 174/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7268 - val_loss: -18.2278\n",
      "Epoch 175/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.6539 - val_loss: -18.6833\n",
      "Epoch 176/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7760 - val_loss: -18.4338\n",
      "Epoch 177/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7536 - val_loss: -18.5710\n",
      "Epoch 178/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7474 - val_loss: -18.6478\n",
      "Epoch 179/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7437 - val_loss: -18.6647\n",
      "Epoch 180/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.6958 - val_loss: -18.6615\n",
      "Epoch 181/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.6887 - val_loss: -18.7023\n",
      "Epoch 182/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.6798 - val_loss: -18.3917\n",
      "Epoch 183/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7503 - val_loss: -18.7028\n",
      "Epoch 184/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.7119 - val_loss: -18.5683\n",
      "Epoch 185/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.6460 - val_loss: -18.6865\n",
      "Epoch 186/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.7461 - val_loss: -17.9106\n",
      "Epoch 187/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7195 - val_loss: -18.6714\n",
      "Epoch 188/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.5478 - val_loss: -18.6427\n",
      "Epoch 189/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7350 - val_loss: -18.6541\n",
      "Epoch 190/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7432 - val_loss: -18.6626\n",
      "Epoch 191/200\n",
      "313/313 [==============================] - 4s 11ms/step - loss: -17.7242 - val_loss: -18.6175\n",
      "Epoch 192/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.6244 - val_loss: -18.6411\n",
      "Epoch 193/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.6730 - val_loss: -18.6384\n",
      "Epoch 194/200\n",
      "313/313 [==============================] - 4s 12ms/step - loss: -17.7371 - val_loss: -18.3102\n",
      "Epoch 195/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7110 - val_loss: -18.6762\n",
      "Epoch 196/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7106 - val_loss: -18.6134\n",
      "Epoch 197/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.6707 - val_loss: -18.6690\n",
      "Epoch 198/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.6484 - val_loss: -18.3422\n",
      "Epoch 199/200\n",
      "313/313 [==============================] - 3s 10ms/step - loss: -17.7066 - val_loss: -18.6901\n",
      "Epoch 200/200\n",
      "313/313 [==============================] - 3s 11ms/step - loss: -17.6813 - val_loss: -18.6511\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_imgs,decoded_imgs = build_cnn_autoencoder_model(profile_pngs_objs, midcurve_pngs_objs)\n",
    "plot_results(original_imgs,decoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pix2pix.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

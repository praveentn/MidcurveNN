{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "notebook_simple_encoderdecoder_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveentn/MidcurveNN/blob/master/notebook_simple_encoderdecoder_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "qmkj-80IHxnd",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_xnMOsbqHz61"
      },
      "source": [
        "# Simple EncoderDecoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwHkho30-ytC",
        "colab_type": "code",
        "outputId": "8b7bc75e-0cbc-4ebb-a1dd-5458d365483d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# mount google drive & set working directory\n",
        "# requires auth (click on url & copy token into text box when prompted)\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "import os\n",
        "print(os.getcwd())\n",
        "\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks/MidcurveNN')\n",
        "!pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content\n",
            "/content/gdrive/My Drive/Colab Notebooks/MidcurveNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz7Wpotd-oFf",
        "colab_type": "text"
      },
      "source": [
        "## Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeapgX0p-oFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# requirements = \"\"\"\n",
        "# keras\n",
        "# git+https://www.github.com/keras-team/keras-contrib.git\n",
        "# matplotlib\n",
        "# numpy\n",
        "# scipy\n",
        "# pillow\n",
        "# #urllib\n",
        "# #skimage\n",
        "# scikit-image\n",
        "# #gzip\n",
        "# #pickle\n",
        "# \"\"\"\n",
        "# %store requirements > requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoRU4Ake-oFj",
        "colab_type": "code",
        "outputId": "38577dcd-afd7-422b-8bd3-553001bfc33f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# !pip install -r requirements.txt\n",
        "!pip install drawSvg"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: drawSvg in /usr/local/lib/python3.6/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from drawSvg) (1.16.4)\n",
            "Requirement already satisfied: cairoSVG in /usr/local/lib/python3.6/dist-packages (from drawSvg) (2.4.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from drawSvg) (2.4.1)\n",
            "Requirement already satisfied: cairocffi in /usr/local/lib/python3.6/dist-packages (from cairoSVG->drawSvg) (1.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from cairoSVG->drawSvg) (4.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from cairoSVG->drawSvg) (0.6.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.6/dist-packages (from cairoSVG->drawSvg) (1.0.2)\n",
            "Requirement already satisfied: cssselect2 in /usr/local/lib/python3.6/dist-packages (from cairoSVG->drawSvg) (0.2.1)\n",
            "Requirement already satisfied: setuptools>=39.2.0 in /usr/local/lib/python3.6/dist-packages (from cairocffi->cairoSVG->drawSvg) (41.0.1)\n",
            "Requirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from cairocffi->cairoSVG->drawSvg) (1.12.3)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->cairoSVG->drawSvg) (0.46)\n",
            "Requirement already satisfied: webencodings>=0.4 in /usr/local/lib/python3.6/dist-packages (from tinycss2->cairoSVG->drawSvg) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.1.0->cairocffi->cairoSVG->drawSvg) (2.19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e1_Y75QXJS6h"
      },
      "source": [
        "## Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YfIk2es3hJEd",
        "outputId": "e92dd4be-56cc-43d3-ca76-ecf253f7bdd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# !pip install tensorflow-gpu==2.0.0-alpha0\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from random import shuffle\n",
        "\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras import regularizers, optimizers\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import Adam,RMSprop,SGD\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\n",
        "from keras import regularizers\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten,AveragePooling2D,UpSampling2D\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "from random import shuffle\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from prepare_data import get_training_data\n",
        "#from prepare_plots import plot_results\n",
        "import random\n",
        "\n",
        "import PIL\n",
        "import json\n",
        "import numpy as np\n",
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "# matplotlib.use('TKAgg')\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iYn4MdZnKCey"
      },
      "source": [
        "## Load the dataset\n",
        "\n",
        "Steps to generate URL used below:\n",
        "- Say, your data files are in the directory called 'input'\n",
        "- Manually create a zip file, 'input.zip'\n",
        "- Sync it to gDrive\n",
        "- In gDrive, Share it with Public model, copy its share-able link\n",
        "- Use https://sites.google.com/site/gdocs2direct/ to generate corresponding Direct link\n",
        "- Paste it below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GMP7R7V-oFq",
        "colab_type": "code",
        "outputId": "d8d4eb89-5d34-4430-c7d1-2b891db7bcb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# test PIL installation\n",
        "import sys\n",
        "from PIL import Image\n",
        "sys.modules['Image'] = Image\n",
        "\n",
        "# both should point to same dir\n",
        "from PIL import Image\n",
        "print(Image.__file__)\n",
        "\n",
        "import Image\n",
        "print(Image.__file__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcMdAhHH3TcT",
        "colab_type": "code",
        "outputId": "0acdd65a-4121-4135-f956-647a6e29ba17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# _URL = 'https://drive.google.com/uc?export=download&id=16rqDFLO__WySSQGlAht0FEj2uJZg4M9M'\n",
        "\n",
        "# path_to_zip = tf.keras.utils.get_file('input.zip',\n",
        "#                                       origin=_URL,\n",
        "#                                       extract=True)\n",
        "\n",
        "# working directory\n",
        "wdir = os.getcwd()\n",
        "print(\"Working directory: \", wdir)\n",
        "\n",
        "# input_data_folder = os.path.join(os.path.dirname(path_to_zip), 'input')\n",
        "input_data_folder = wdir + \"/data/input\"\n",
        "input_data_folder = wdir + \"/data/images\"\n",
        "print(\"input data dir: \", input_data_folder)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Working directory:  /content/gdrive/My Drive/Colab Notebooks/MidcurveNN\n",
            "input data dir:  /content/gdrive/My Drive/Colab Notebooks/MidcurveNN/data/images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1iMlSMN3UeK",
        "colab_type": "code",
        "outputId": "054ac148-35de-40c0-e4b1-611b54117e6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import glob\n",
        "\n",
        "image_paths = glob.glob(input_data_folder + '/**/*.png', recursive=True)\n",
        "images = [os.path.basename(img_path) for img_path in image_paths]\n",
        "\n",
        "print(len(images))\n",
        "\n",
        "#images = os.listdir(input_data_folder)\n",
        "images[99]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'CapI_Midcurve_mirrored_0_translated_10_-20.png'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGmCaN2vFWyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imdim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO04QsT-3faS",
        "colab_type": "code",
        "outputId": "3344866b-61de-44b3-f860-58849d6aa1bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "shapes = os.listdir('/content/gdrive/My Drive/Colab Notebooks/MidcurveNN/data/images')\n",
        "shapes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CapI',\n",
              " 'Plus',\n",
              " 'Iuvw',\n",
              " 'Luvw',\n",
              " 'SqLu',\n",
              " 'Tuvw',\n",
              " 'Vuvw',\n",
              " 'Sm_n',\n",
              " 'InvV',\n",
              " 'Parl',\n",
              " 'Trap',\n",
              " 'Stik',\n",
              " 'Usla',\n",
              " 'LapT',\n",
              " 'RelY',\n",
              " 'T002',\n",
              " 'T003',\n",
              " 'T004']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrYBelpQ-oFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_input_image_pairs(datafolder=input_data_folder):\n",
        "    profile_pngs = []\n",
        "    midcurve_pngs = []\n",
        "    for file in os.listdir(datafolder):\n",
        "        fullpath = os.path.join(datafolder, file)\n",
        "        if os.path.isdir(fullpath):\n",
        "            continue\n",
        "        if file.endswith(\".png\"):\n",
        "            if file.find(\"Profile\") != -1:\n",
        "                profile_pngs.append(fullpath)\n",
        "            if file.find(\"Midcurve\") != -1:\n",
        "                midcurve_pngs.append(fullpath)\n",
        "    profile_pngs = sorted(profile_pngs)\n",
        "    midcurve_pngs = sorted(midcurve_pngs)\n",
        "    return profile_pngs,midcurve_pngs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2CbTEt448b4R",
        "colab": {}
      },
      "source": [
        "def get_training_data(datafolder=input_data_folder):\n",
        "    profile_pngs,midcurve_pngs = read_input_image_pairs(datafolder)\n",
        "    \n",
        "    profile_pngs_objs = [img_to_array(load_img(f, color_mode='rgba', target_size=(imdim, imdim))) for f in profile_pngs ]\n",
        "    midcurve_pngs_objs = [img_to_array(load_img(f, color_mode='rgba', target_size=(imdim, imdim))) for f in midcurve_pngs]\n",
        "\n",
        "#     profile_pngs_objs = np.array([x.reshape((1,) + x.shape) for x in profile_pngs_objs])\n",
        "#     midcurve_pngs_objs = np.array([x.reshape((1,) + x.shape) for x in midcurve_pngs_objs])\n",
        "\n",
        "    profile_pngs_gray_objs = [x[:,:,3] for x in profile_pngs_objs]\n",
        "    midcurve_pngs_gray_objs =[x[:,:,3] for x in midcurve_pngs_objs]\n",
        "    \n",
        "#     profile_pngs_gray_objs = [np.where(x>128, 0, 1) for x in profile_pngs_gray_objs]\n",
        "#     midcurve_pngs_gray_objs =[np.where(x>128, 0, 1) for x in midcurve_pngs_gray_objs]\n",
        "        \n",
        "    # shufle them\n",
        "    zipped_profiles_midcurves = [(p,m) for p,m in zip(profile_pngs_gray_objs,midcurve_pngs_gray_objs)]\n",
        "    shuffle(zipped_profiles_midcurves)\n",
        "    profile_pngs_gray_objs, midcurve_pngs_gray_objs = zip(*zipped_profiles_midcurves)\n",
        "    \n",
        "    return profile_pngs_gray_objs, midcurve_pngs_gray_objs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgR0H_-d4Mvq",
        "colab_type": "code",
        "outputId": "1f7aa7d3-e94a-436a-b3fc-adafb564975b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "profile_pngs_objs = ()\n",
        "midcurve_pngs_objs = ()\n",
        "\n",
        "for shape in shapes:\n",
        "    print(shape)\n",
        "    tp, tm = get_training_data(os.path.join(input_data_folder, shape))\n",
        "    profile_pngs_objs += tp\n",
        "    midcurve_pngs_objs += tm\n",
        "    print(len(profile_pngs_objs), len(midcurve_pngs_objs))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CapI\n",
            "112 112\n",
            "Plus\n",
            "224 224\n",
            "Iuvw\n",
            "336 336\n",
            "Luvw\n",
            "448 448\n",
            "SqLu\n",
            "560 560\n",
            "Tuvw\n",
            "672 672\n",
            "Vuvw\n",
            "784 784\n",
            "Sm_n\n",
            "896 896\n",
            "InvV\n",
            "1008 1008\n",
            "Parl\n",
            "1120 1120\n",
            "Trap\n",
            "1232 1232\n",
            "Stik\n",
            "1344 1344\n",
            "Usla\n",
            "1456 1456\n",
            "LapT\n",
            "1568 1568\n",
            "RelY\n",
            "1680 1680\n",
            "T002\n",
            "1792 1792\n",
            "T003\n",
            "1904 1904\n",
            "T004\n",
            "2016 2016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4OLHMpsQ5aOv",
        "colab": {}
      },
      "source": [
        "#profile_pngs_objs, midcurve_pngs_objs = get_training_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gogvpFi9-oF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_results(original_imgs,computed_imgs):\n",
        "    n = 10  # how many digits we will display\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(n):\n",
        "        # display original\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(original_imgs[i].reshape(100, 100),cmap='gray_r')\n",
        "#         plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "        # display reconstruction\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(computed_imgs[i].reshape(100, 100),cmap='gray_r')\n",
        "#         plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT489k6k-oF8",
        "colab_type": "code",
        "outputId": "93a50da3-6ceb-4da1-80ab-e3a753d6333e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "plot_results(profile_pngs_objs, midcurve_pngs_objs)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAADjCAYAAADdR/IFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIIj/A7eWOEN4edA8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEgxZ1WD-oGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class simple_encoderdecoder:\n",
        "    def __init__(self):\n",
        "        self.encoding_dim = 100\n",
        "        self.input_dim = 10000\n",
        "        self.epochs = 200\n",
        "        self.autoencoder_model_pkl = \"models/autoencoder_model.pkl\"\n",
        "        self.encoder_model_pkl = \"models/encoder_model.pkl\"\n",
        "        self.decoder_model_pkl = \"models/decoder_model.pkl\"\n",
        "                \n",
        "    def process_images(self,grayobjs):\n",
        "        flat_objs = [x.reshape(self.input_dim) for x in grayobjs]\n",
        "        pngs_objs = np.array(flat_objs)\n",
        "        return pngs_objs\n",
        "\n",
        "    def train(self,\n",
        "            profile_pngs_gray_objs, \n",
        "            midcurve_pngs_gray_objs):\n",
        "        \n",
        "        if not os.path.exists(self.autoencoder_model_pkl):\n",
        "            # this is our input placeholder\n",
        "            input_img = Input(shape=(self.input_dim,))\n",
        "            \n",
        "            # \"encoded\" is the encoded representation of the input\n",
        "            encoded = Dense(self.encoding_dim, activation='relu',activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
        "            # \"decoded\" is the lossy reconstruction of the input\n",
        "            decoded = Dense(self.input_dim, activation='sigmoid')(encoded) \n",
        "            \n",
        "            # Model 1: Full AutoEncoder, includes both encoder single dense layer and decoder single dense layer. \n",
        "            # This model maps an input to its reconstruction\n",
        "            self.autoencoder = Model(input_img, decoded)\n",
        "                    \n",
        "            # Model 2: a separate encoder model: -------------------\n",
        "            # this model maps an input to its encoded representation\n",
        "            self.encoder = Model(input_img, encoded)\n",
        "            \n",
        "            # Model 3: a separate encoder model: -------------------\n",
        "            # create a placeholder for an encoded (32-dimensional) input\n",
        "            encoded_input = Input(shape=(self.encoding_dim,))\n",
        "            # retrieve the last layer of the autoencoder model\n",
        "            decoder_layer = self.autoencoder.layers[-1]\n",
        "            # create the decoder model\n",
        "            self.decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
        "            \n",
        "            # Compilation of Autoencoder (only)\n",
        "            self.autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "            \n",
        "            profile_pngs_objs = self.process_images(profile_pngs_gray_objs)\n",
        "            midcurve_pngs_objs = self.process_images(midcurve_pngs_gray_objs)\n",
        "                \n",
        "            self.x = profile_pngs_objs\n",
        "            self.y = midcurve_pngs_objs\n",
        "            self.autoencoder.fit(self.x, self.y,\n",
        "                        epochs=self.epochs,\n",
        "                        batch_size=5,\n",
        "                        shuffle=True)                \n",
        "            # Save models\n",
        "            #self.autoencoder.save(self.autoencoder_model_pkl)\n",
        "            #self.encoder.save(self.encoder_model_pkl)\n",
        "            #self.decoder.save(self.decoder_model_pkl)  \n",
        "        else:\n",
        "            # Save models\n",
        "            #self.autoencoder = load_model(self.autoencoder_model_pkl)\n",
        "            #self.encoder= load_model(self.encoder_model_pkl)\n",
        "            #self.decoder = load_model(self.decoder_model_pkl)\n",
        "            print(\"pass...\")\n",
        "    \n",
        "    def predict(self, test_profile_images):\n",
        "        png_profile_images = self.process_images(test_profile_images)\n",
        "        encoded_imgs = self.encoder.predict(png_profile_images)\n",
        "        decoded_imgs = self.decoder.predict(encoded_imgs)    \n",
        "        return test_profile_images,decoded_imgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp_A3YTfCWAJ",
        "colab_type": "code",
        "outputId": "e8ba0942-7dd2-489b-e25a-463a6587ccff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "endec = simple_encoderdecoder()\n",
        "endec.train(profile_pngs_objs, midcurve_pngs_objs)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0819 14:32:00.991422 139829684549504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0819 14:32:01.012872 139829684549504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0819 14:32:01.021766 139829684549504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0819 14:32:01.071669 139829684549504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0819 14:32:01.091976 139829684549504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0819 14:32:01.100994 139829684549504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0819 14:32:01.501285 139829684549504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "2016/2016 [==============================] - 4s 2ms/step - loss: -1.2215\n",
            "Epoch 2/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -6.5519\n",
            "Epoch 3/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -7.8554\n",
            "Epoch 4/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1903\n",
            "Epoch 5/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.3732\n",
            "Epoch 6/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.3984\n",
            "Epoch 7/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.3921\n",
            "Epoch 8/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.3140\n",
            "Epoch 9/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.3230\n",
            "Epoch 10/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2964\n",
            "Epoch 11/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.3069\n",
            "Epoch 12/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2890\n",
            "Epoch 13/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2187\n",
            "Epoch 14/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2786\n",
            "Epoch 15/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2306\n",
            "Epoch 16/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2810\n",
            "Epoch 17/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2052\n",
            "Epoch 18/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2462\n",
            "Epoch 19/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2254\n",
            "Epoch 20/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2254\n",
            "Epoch 21/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2175\n",
            "Epoch 22/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2529\n",
            "Epoch 23/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1995\n",
            "Epoch 24/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1861\n",
            "Epoch 25/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2441\n",
            "Epoch 26/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1940\n",
            "Epoch 27/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1949\n",
            "Epoch 28/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2227\n",
            "Epoch 29/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2219\n",
            "Epoch 30/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1872\n",
            "Epoch 31/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1739\n",
            "Epoch 32/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1880\n",
            "Epoch 33/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1960\n",
            "Epoch 34/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2063\n",
            "Epoch 35/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1712\n",
            "Epoch 36/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2071\n",
            "Epoch 37/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2045\n",
            "Epoch 38/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1802\n",
            "Epoch 39/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1988\n",
            "Epoch 40/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2011\n",
            "Epoch 41/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1932\n",
            "Epoch 42/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1908\n",
            "Epoch 43/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2124\n",
            "Epoch 44/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1966\n",
            "Epoch 45/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2108\n",
            "Epoch 46/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1862\n",
            "Epoch 47/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1875\n",
            "Epoch 48/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2049\n",
            "Epoch 49/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1934\n",
            "Epoch 50/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2027\n",
            "Epoch 51/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1961\n",
            "Epoch 52/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2008\n",
            "Epoch 53/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2380\n",
            "Epoch 54/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2058\n",
            "Epoch 55/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.1886\n",
            "Epoch 56/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2212\n",
            "Epoch 57/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2007\n",
            "Epoch 58/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2188\n",
            "Epoch 59/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2447\n",
            "Epoch 60/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2010\n",
            "Epoch 61/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2173\n",
            "Epoch 62/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2515\n",
            "Epoch 63/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2394\n",
            "Epoch 64/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2153\n",
            "Epoch 65/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2265\n",
            "Epoch 66/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2442\n",
            "Epoch 67/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2260\n",
            "Epoch 68/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2652\n",
            "Epoch 69/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2308\n",
            "Epoch 70/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2563\n",
            "Epoch 71/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2287\n",
            "Epoch 72/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2507\n",
            "Epoch 73/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2231\n",
            "Epoch 74/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2437\n",
            "Epoch 75/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2477\n",
            "Epoch 76/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2289\n",
            "Epoch 77/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2806\n",
            "Epoch 78/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2526\n",
            "Epoch 79/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2274\n",
            "Epoch 80/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2329\n",
            "Epoch 81/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2739\n",
            "Epoch 82/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2202\n",
            "Epoch 83/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2769\n",
            "Epoch 84/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2192\n",
            "Epoch 85/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2732\n",
            "Epoch 86/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2524\n",
            "Epoch 87/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2479\n",
            "Epoch 88/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2628\n",
            "Epoch 89/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2729\n",
            "Epoch 90/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2375\n",
            "Epoch 91/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2629\n",
            "Epoch 92/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2553\n",
            "Epoch 93/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2796\n",
            "Epoch 94/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2610\n",
            "Epoch 95/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2348\n",
            "Epoch 96/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2618\n",
            "Epoch 97/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2463\n",
            "Epoch 98/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2581\n",
            "Epoch 99/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2860\n",
            "Epoch 100/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2529\n",
            "Epoch 101/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2669\n",
            "Epoch 102/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2652\n",
            "Epoch 103/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2687\n",
            "Epoch 104/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2733\n",
            "Epoch 105/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.3040\n",
            "Epoch 106/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2232\n",
            "Epoch 107/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2292\n",
            "Epoch 108/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2666\n",
            "Epoch 109/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2262\n",
            "Epoch 110/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2885\n",
            "Epoch 111/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2608\n",
            "Epoch 112/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.3004\n",
            "Epoch 113/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2229\n",
            "Epoch 114/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2957\n",
            "Epoch 115/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2401\n",
            "Epoch 116/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2614\n",
            "Epoch 117/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2562\n",
            "Epoch 118/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2456\n",
            "Epoch 119/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2435\n",
            "Epoch 120/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2299\n",
            "Epoch 121/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2772\n",
            "Epoch 122/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2365\n",
            "Epoch 123/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2441\n",
            "Epoch 124/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2771\n",
            "Epoch 125/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2430\n",
            "Epoch 126/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2823\n",
            "Epoch 127/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2644\n",
            "Epoch 128/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2492\n",
            "Epoch 129/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2474\n",
            "Epoch 130/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2775\n",
            "Epoch 131/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2486\n",
            "Epoch 132/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2629\n",
            "Epoch 133/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2667\n",
            "Epoch 134/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2612\n",
            "Epoch 135/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2591\n",
            "Epoch 136/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2722\n",
            "Epoch 137/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2655\n",
            "Epoch 138/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2635\n",
            "Epoch 139/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2708\n",
            "Epoch 140/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2741\n",
            "Epoch 141/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2617\n",
            "Epoch 142/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2552\n",
            "Epoch 143/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2515\n",
            "Epoch 144/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2303\n",
            "Epoch 145/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2997\n",
            "Epoch 146/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2759\n",
            "Epoch 147/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2611\n",
            "Epoch 148/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2712\n",
            "Epoch 149/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2927\n",
            "Epoch 150/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2357\n",
            "Epoch 151/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2512\n",
            "Epoch 152/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2655\n",
            "Epoch 153/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2360\n",
            "Epoch 154/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2587\n",
            "Epoch 155/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2563\n",
            "Epoch 156/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2503\n",
            "Epoch 157/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2706\n",
            "Epoch 158/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2651\n",
            "Epoch 159/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2982\n",
            "Epoch 160/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2481\n",
            "Epoch 161/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2555\n",
            "Epoch 162/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2713\n",
            "Epoch 163/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2592\n",
            "Epoch 164/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2361\n",
            "Epoch 165/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2607\n",
            "Epoch 166/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2542\n",
            "Epoch 167/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2899\n",
            "Epoch 168/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2275\n",
            "Epoch 169/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2545\n",
            "Epoch 170/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2455\n",
            "Epoch 171/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2459\n",
            "Epoch 172/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2819\n",
            "Epoch 173/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2606\n",
            "Epoch 174/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2800\n",
            "Epoch 175/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2570\n",
            "Epoch 176/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2652\n",
            "Epoch 177/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2684\n",
            "Epoch 178/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2370\n",
            "Epoch 179/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2813\n",
            "Epoch 180/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2532\n",
            "Epoch 181/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2384\n",
            "Epoch 182/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2538\n",
            "Epoch 183/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2916\n",
            "Epoch 184/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2352\n",
            "Epoch 185/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2552\n",
            "Epoch 186/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2379\n",
            "Epoch 187/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2610\n",
            "Epoch 188/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2604\n",
            "Epoch 189/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2575\n",
            "Epoch 190/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2385\n",
            "Epoch 191/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2601\n",
            "Epoch 192/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2738\n",
            "Epoch 193/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2620\n",
            "Epoch 194/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2288\n",
            "Epoch 195/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2719\n",
            "Epoch 196/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2462\n",
            "Epoch 197/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2604\n",
            "Epoch 198/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2405\n",
            "Epoch 199/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2463\n",
            "Epoch 200/200\n",
            "2016/2016 [==============================] - 3s 1ms/step - loss: -8.2674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RxkuCP_EXkE",
        "colab_type": "code",
        "outputId": "aba8ff24-e968-48c3-883a-ffb41a425d5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "test_gray_images = random.sample(profile_pngs_objs, 10)\n",
        "original_profile_imgs, predicted_midcurve_imgs = endec.predict(test_gray_images)\n",
        "\n",
        "plot_results(original_profile_imgs, predicted_midcurve_imgs)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAADjCAYAAADdR/IFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMjHxZiKCyu5",
        "colab_type": "code",
        "outputId": "08d347a0-5972-48b7-9173-650ce6b60662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "test_gray_images = random.sample(profile_pngs_objs, 10)\n",
        "original_profile_imgs, predicted_midcurve_imgs = endec.predict(test_gray_images)\n",
        "\n",
        "plot_results(original_profile_imgs, predicted_midcurve_imgs)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAADjCAYAAADdR/IFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTghqAAAAAHJCUAMAAACQE/8PEfspmdMhIYYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt7ygs5deVBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "notebook_simple_encoderdecoder_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveentn/MidcurveNN/blob/master/notebook_simple_encoderdecoder_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "qmkj-80IHxnd",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_xnMOsbqHz61"
      },
      "source": [
        "# Simple EncoderDecoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwHkho30-ytC",
        "colab_type": "code",
        "outputId": "ffafbc58-dae9-4f66-8fdc-6d01eb58d134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        }
      },
      "source": [
        "# mount google drive & set working directory\n",
        "# requires auth (click on url & copy token into text box when prompted)\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "import os\n",
        "print(os.getcwd())\n",
        "\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks/MidcurveNN')\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E0818 09:36:35.889911 140021893597056 ultratb.py:152] Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-74-d7cda7460339>\", line 5, in <module>\n",
            "    print(os.getcwd())\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 725, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz7Wpotd-oFf",
        "colab_type": "text"
      },
      "source": [
        "## Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeapgX0p-oFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# requirements = \"\"\"\n",
        "# keras\n",
        "# git+https://www.github.com/keras-team/keras-contrib.git\n",
        "# matplotlib\n",
        "# numpy\n",
        "# scipy\n",
        "# pillow\n",
        "# #urllib\n",
        "# #skimage\n",
        "# scikit-image\n",
        "# #gzip\n",
        "# #pickle\n",
        "# \"\"\"\n",
        "# %store requirements > requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoRU4Ake-oFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install -r requirements.txt\n",
        "!pip install drawSvg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e1_Y75QXJS6h"
      },
      "source": [
        "## Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YfIk2es3hJEd",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# !pip install tensorflow-gpu==2.0.0-alpha0\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from random import shuffle\n",
        "\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras import regularizers, optimizers\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import Adam,RMSprop,SGD\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\n",
        "from keras import regularizers\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten,AveragePooling2D,UpSampling2D\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "from random import shuffle\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from prepare_data import get_training_data\n",
        "#from prepare_plots import plot_results\n",
        "import random\n",
        "\n",
        "import PIL\n",
        "import json\n",
        "import numpy as np\n",
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "# matplotlib.use('TKAgg')\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iYn4MdZnKCey"
      },
      "source": [
        "## Load the dataset\n",
        "\n",
        "Steps to generate URL used below:\n",
        "- Say, your data files are in the directory called 'input'\n",
        "- Manually create a zip file, 'input.zip'\n",
        "- Sync it to gDrive\n",
        "- In gDrive, Share it with Public model, copy its share-able link\n",
        "- Use https://sites.google.com/site/gdocs2direct/ to generate corresponding Direct link\n",
        "- Paste it below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GMP7R7V-oFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test PIL installation\n",
        "import sys\n",
        "from PIL import Image\n",
        "sys.modules['Image'] = Image\n",
        "\n",
        "# both should point to same dir\n",
        "from PIL import Image\n",
        "print(Image.__file__)\n",
        "\n",
        "import Image\n",
        "print(Image.__file__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcMdAhHH3TcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# _URL = 'https://drive.google.com/uc?export=download&id=16rqDFLO__WySSQGlAht0FEj2uJZg4M9M'\n",
        "\n",
        "# path_to_zip = tf.keras.utils.get_file('input.zip',\n",
        "#                                       origin=_URL,\n",
        "#                                       extract=True)\n",
        "\n",
        "# working directory\n",
        "wdir = os.getcwd()\n",
        "print(\"Working directory: \", wdir)\n",
        "\n",
        "# input_data_folder = os.path.join(os.path.dirname(path_to_zip), 'input')\n",
        "input_data_folder = wdir + \"/data/input\"\n",
        "input_data_folder = wdir + \"/data/images\"\n",
        "print(\"input data dir: \", input_data_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1iMlSMN3UeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "\n",
        "image_paths = glob.glob(input_data_folder + '/**/*.png', recursive=True)\n",
        "images = [os.path.basename(img_path) for img_path in image_paths]\n",
        "\n",
        "print(len(images))\n",
        "\n",
        "#images = os.listdir(input_data_folder)\n",
        "images[99]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGmCaN2vFWyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imdim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO04QsT-3faS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shapes = os.listdir('/content/gdrive/My Drive/Colab Notebooks/MidcurveNN/data/images')\n",
        "shapes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrYBelpQ-oFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_input_image_pairs(datafolder=input_data_folder):\n",
        "    profile_pngs = []\n",
        "    midcurve_pngs = []\n",
        "    for file in os.listdir(datafolder):\n",
        "        fullpath = os.path.join(datafolder, file)\n",
        "        if os.path.isdir(fullpath):\n",
        "            continue\n",
        "        if file.endswith(\".png\"):\n",
        "            if file.find(\"Profile\") != -1:\n",
        "                profile_pngs.append(fullpath)\n",
        "            if file.find(\"Midcurve\") != -1:\n",
        "                midcurve_pngs.append(fullpath)\n",
        "    profile_pngs = sorted(profile_pngs)\n",
        "    midcurve_pngs = sorted(midcurve_pngs)\n",
        "    return profile_pngs,midcurve_pngs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2CbTEt448b4R",
        "colab": {}
      },
      "source": [
        "def get_training_data(datafolder=input_data_folder):\n",
        "    profile_pngs,midcurve_pngs = read_input_image_pairs(datafolder)\n",
        "    \n",
        "    profile_pngs_objs = [img_to_array(load_img(f, color_mode='rgba', target_size=(imdim, imdim))) for f in profile_pngs ]\n",
        "    midcurve_pngs_objs = [img_to_array(load_img(f, color_mode='rgba', target_size=(imdim, imdim))) for f in midcurve_pngs]\n",
        "\n",
        "#     profile_pngs_objs = np.array([x.reshape((1,) + x.shape) for x in profile_pngs_objs])\n",
        "#     midcurve_pngs_objs = np.array([x.reshape((1,) + x.shape) for x in midcurve_pngs_objs])\n",
        "\n",
        "    profile_pngs_gray_objs = [x[:,:,3] for x in profile_pngs_objs]\n",
        "    midcurve_pngs_gray_objs =[x[:,:,3] for x in midcurve_pngs_objs]\n",
        "    \n",
        "#     profile_pngs_gray_objs = [np.where(x>128, 0, 1) for x in profile_pngs_gray_objs]\n",
        "#     midcurve_pngs_gray_objs =[np.where(x>128, 0, 1) for x in midcurve_pngs_gray_objs]\n",
        "        \n",
        "    # shufle them\n",
        "    zipped_profiles_midcurves = [(p,m) for p,m in zip(profile_pngs_gray_objs,midcurve_pngs_gray_objs)]\n",
        "    shuffle(zipped_profiles_midcurves)\n",
        "    profile_pngs_gray_objs, midcurve_pngs_gray_objs = zip(*zipped_profiles_midcurves)\n",
        "    \n",
        "    return profile_pngs_gray_objs, midcurve_pngs_gray_objs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgR0H_-d4Mvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "profile_pngs_objs = ()\n",
        "midcurve_pngs_objs = ()\n",
        "\n",
        "for shape in shapes:\n",
        "    print(shape)\n",
        "    tp, tm = get_training_data(os.path.join(input_data_folder, shape))\n",
        "    profile_pngs_objs += tp\n",
        "    midcurve_pngs_objs += tm\n",
        "    print(len(profile_pngs_objs), len(midcurve_pngs_objs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4OLHMpsQ5aOv",
        "colab": {}
      },
      "source": [
        "#profile_pngs_objs, midcurve_pngs_objs = get_training_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gogvpFi9-oF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_results(original_imgs,computed_imgs):\n",
        "    n = 10  # how many digits we will display\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(n):\n",
        "        # display original\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(original_imgs[i].reshape(100, 100),cmap='gray_r')\n",
        "#         plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "        # display reconstruction\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(computed_imgs[i].reshape(100, 100),cmap='gray_r')\n",
        "#         plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT489k6k-oF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results(profile_pngs_objs, midcurve_pngs_objs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEgxZ1WD-oGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class simple_encoderdecoder:\n",
        "    def __init__(self):\n",
        "        self.encoding_dim = 100\n",
        "        self.input_dim = 10000\n",
        "        self.epochs = 50\n",
        "        self.autoencoder_model_pkl = \"models/autoencoder_model.pkl\"\n",
        "        self.encoder_model_pkl = \"models/encoder_model.pkl\"\n",
        "        self.decoder_model_pkl = \"models/decoder_model.pkl\"\n",
        "                \n",
        "    def process_images(self,grayobjs):\n",
        "        flat_objs = [x.reshape(self.input_dim) for x in grayobjs]\n",
        "        pngs_objs = np.array(flat_objs)\n",
        "        return pngs_objs\n",
        "\n",
        "    def train(self,\n",
        "            profile_pngs_gray_objs, \n",
        "            midcurve_pngs_gray_objs):\n",
        "        \n",
        "        if not os.path.exists(self.autoencoder_model_pkl):\n",
        "            # this is our input placeholder\n",
        "            input_img = Input(shape=(self.input_dim,))\n",
        "            \n",
        "            # \"encoded\" is the encoded representation of the input\n",
        "            encoded = Dense(self.encoding_dim, activation='relu',activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
        "            # \"decoded\" is the lossy reconstruction of the input\n",
        "            decoded = Dense(self.input_dim, activation='sigmoid')(encoded) \n",
        "            \n",
        "            # Model 1: Full AutoEncoder, includes both encoder single dense layer and decoder single dense layer. \n",
        "            # This model maps an input to its reconstruction\n",
        "            self.autoencoder = Model(input_img, decoded)\n",
        "                    \n",
        "            # Model 2: a separate encoder model: -------------------\n",
        "            # this model maps an input to its encoded representation\n",
        "            self.encoder = Model(input_img, encoded)\n",
        "            \n",
        "            # Model 3: a separate encoder model: -------------------\n",
        "            # create a placeholder for an encoded (32-dimensional) input\n",
        "            encoded_input = Input(shape=(self.encoding_dim,))\n",
        "            # retrieve the last layer of the autoencoder model\n",
        "            decoder_layer = self.autoencoder.layers[-1]\n",
        "            # create the decoder model\n",
        "            self.decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
        "            \n",
        "            # Compilation of Autoencoder (only)\n",
        "            self.autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "            \n",
        "            profile_pngs_objs = self.process_images(profile_pngs_gray_objs)\n",
        "            midcurve_pngs_objs = self.process_images(midcurve_pngs_gray_objs)\n",
        "                \n",
        "            self.x = profile_pngs_objs\n",
        "            self.y = midcurve_pngs_objs\n",
        "            self.autoencoder.fit(self.x, self.y,\n",
        "                        epochs=self.epochs,\n",
        "                        batch_size=5,\n",
        "                        shuffle=True)                \n",
        "            # Save models\n",
        "            #self.autoencoder.save(self.autoencoder_model_pkl)\n",
        "            #self.encoder.save(self.encoder_model_pkl)\n",
        "            #self.decoder.save(self.decoder_model_pkl)  \n",
        "        else:\n",
        "            # Save models\n",
        "            #self.autoencoder = load_model(self.autoencoder_model_pkl)\n",
        "            #self.encoder= load_model(self.encoder_model_pkl)\n",
        "            #self.decoder = load_model(self.decoder_model_pkl)\n",
        "            print(\"pass...\")\n",
        "    \n",
        "    def predict(self, test_profile_images):\n",
        "        png_profile_images = self.process_images(test_profile_images)\n",
        "        encoded_imgs = self.encoder.predict(png_profile_images)\n",
        "        decoded_imgs = self.decoder.predict(encoded_imgs)    \n",
        "        return test_profile_images,decoded_imgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp_A3YTfCWAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "endec = simple_encoderdecoder()\n",
        "endec.train(profile_pngs_objs, midcurve_pngs_objs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RxkuCP_EXkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gray_images = random.sample(profile_pngs_objs, 10)\n",
        "original_profile_imgs, predicted_midcurve_imgs = endec.predict(test_gray_images)\n",
        "\n",
        "plot_results(original_profile_imgs, predicted_midcurve_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMjHxZiKCyu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}

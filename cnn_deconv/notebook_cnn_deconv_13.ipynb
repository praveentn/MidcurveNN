{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "notebook_cnn_deconv_13.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveentn/MidcurveNN/blob/master/cnn_deconv/notebook_cnn_deconv_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQVJL5mHwPrl",
        "colab_type": "text"
      },
      "source": [
        "# CNN ENC-DEC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxYRQhxBxAbv",
        "colab_type": "code",
        "outputId": "1cf74d97-7e43-4ffa-bb5c-864c663a6eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# mount google drive & set working directory\n",
        "# requires auth (click on url & copy token into text box when prompted)\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "import os\n",
        "print(os.getcwd())\n",
        "\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks/MidcurveNN')\n",
        "!pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content\n",
            "/content/gdrive/My Drive/Colab Notebooks/MidcurveNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDHgEuJBwPrm",
        "colab_type": "code",
        "outputId": "20ca5671-7462-4b95-8c7b-814818d2c538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# !pip install tensorflow-gpu==2.0.0-alpha0\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import PIL\n",
        "import json\n",
        "import time\n",
        "\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "from keras import regularizers, optimizers\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Conv2D, UpSampling2D, Reshape, Flatten\n",
        "from keras.layers import GlobalMaxPooling2D, AveragePooling2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "from random import shuffle\n",
        "\n",
        "import numpy as np\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import matplotlib\n",
        "# matplotlib.use('TKAgg')\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evVd6EPUwPrs",
        "colab_type": "code",
        "outputId": "2b3d79e4-619e-42c7-dd0e-0f49914f74fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# working directory\n",
        "wdir = os.getcwd()\n",
        "wdir"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/Colab Notebooks/MidcurveNN'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxFdYYywwPrx",
        "colab_type": "code",
        "outputId": "00076c71-41be-4986-ce4b-fd85a3548526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# _URL = 'https://drive.google.com/uc?export=download&id=16rqDFLO__WySSQGlAht0FEj2uJZg4M9M'\n",
        "\n",
        "# path_to_zip = tf.keras.utils.get_file('input.zip',\n",
        "#                                       origin=_URL,\n",
        "#                                       extract=True)\n",
        "\n",
        "# input_data_folder = os.path.join(os.path.dirname(path_to_zip), 'input')\n",
        "input_data_folder = wdir + \"/data/input\"\n",
        "input_data_folder = wdir + \"/data/images\"\n",
        "print(\"input data dir: \", input_data_folder)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input data dir:  /content/gdrive/My Drive/Colab Notebooks/MidcurveNN/data/images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geTVDZfzPY-u",
        "colab_type": "code",
        "outputId": "1bcef786-508e-4fe6-c099-0fba785a5542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import glob\n",
        "\n",
        "image_paths = glob.glob(input_data_folder + '/**/*.png', recursive=True)\n",
        "images = [os.path.basename(img_path) for img_path in image_paths]\n",
        "\n",
        "print(len(images))\n",
        "\n",
        "#images = os.listdir(input_data_folder)\n",
        "images[99]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6944\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'CapI_Midcurve_mirrored_0_translated_10_-20.png'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNZW79Q1URmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image dimension\n",
        "imdim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjdmJfpRwPr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_input_image_pairs(datafolder=input_data_folder):\n",
        "    profile_pngs = []\n",
        "    midcurve_pngs = []\n",
        "    for file in os.listdir(datafolder):\n",
        "        fullpath = os.path.join(datafolder, file)\n",
        "        if os.path.isdir(fullpath):\n",
        "            continue\n",
        "        if file.endswith(\".png\"):\n",
        "            if file.find(\"Profile\") != -1:\n",
        "                profile_pngs.append(fullpath)\n",
        "            if file.find(\"Midcurve\") != -1:\n",
        "                midcurve_pngs.append(fullpath)\n",
        "    profile_pngs = sorted(profile_pngs)\n",
        "    midcurve_pngs = sorted(midcurve_pngs)\n",
        "    return profile_pngs,midcurve_pngs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rim24hWkwPr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_training_data(datafolder=input_data_folder):\n",
        "    profile_pngs,midcurve_pngs = read_input_image_pairs(datafolder)\n",
        "    \n",
        "    profile_pngs_objs = [img_to_array(load_img(f, color_mode='rgba', target_size=(imdim, imdim))) for f in profile_pngs ]\n",
        "    midcurve_pngs_objs = [img_to_array(load_img(f, color_mode='rgba', target_size=(imdim, imdim))) for f in midcurve_pngs]\n",
        "\n",
        "#     profile_pngs_objs = np.array([x.reshape((1,) + x.shape) for x in profile_pngs_objs])\n",
        "#     midcurve_pngs_objs = np.array([x.reshape((1,) + x.shape) for x in midcurve_pngs_objs])\n",
        "\n",
        "    profile_pngs_gray_objs = [x[:,:,3] for x in profile_pngs_objs]\n",
        "    midcurve_pngs_gray_objs =[x[:,:,3] for x in midcurve_pngs_objs]\n",
        "    \n",
        "#     profile_pngs_gray_objs = [np.where(x>128, 0, 1) for x in profile_pngs_gray_objs]\n",
        "#     midcurve_pngs_gray_objs =[np.where(x>128, 0, 1) for x in midcurve_pngs_gray_objs]\n",
        "        \n",
        "    # shufle them\n",
        "    zipped_profiles_midcurves = [(p,m) for p,m in zip(profile_pngs_gray_objs,midcurve_pngs_gray_objs)]\n",
        "    shuffle(zipped_profiles_midcurves)\n",
        "    profile_pngs_gray_objs, midcurve_pngs_gray_objs = zip(*zipped_profiles_midcurves)\n",
        "    \n",
        "    return profile_pngs_gray_objs, midcurve_pngs_gray_objs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEfyWOYCiYxD",
        "colab_type": "code",
        "outputId": "3dbf8697-b5f3-4b9e-81de-9689f575811d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "shapes = os.listdir('/content/gdrive/My Drive/Colab Notebooks/MidcurveNN/data/images')\n",
        "shapes"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CapI',\n",
              " 'Iuvw',\n",
              " 'Tuvw',\n",
              " 'Vuvw',\n",
              " 'Sm_n',\n",
              " 'InvV',\n",
              " 'Parl',\n",
              " 'Trap',\n",
              " 'Stik',\n",
              " 'Usla',\n",
              " 'LapT',\n",
              " 'RelY',\n",
              " 'T002',\n",
              " 'T003',\n",
              " 'T004',\n",
              " 'T005',\n",
              " 'Plus',\n",
              " 'SqLu',\n",
              " 'Luvw',\n",
              " 'L001',\n",
              " 'L002',\n",
              " 'L003',\n",
              " 'T006',\n",
              " 'X001',\n",
              " 'L004',\n",
              " 'Y001',\n",
              " 'L100',\n",
              " 'Stp1',\n",
              " 'I100',\n",
              " 'I101',\n",
              " 'L005']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP3POQEVtlck",
        "colab_type": "code",
        "outputId": "ed2718a5-17d0-4a98-8b98-427d9467f9cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "profile_pngs_objs = ()\n",
        "midcurve_pngs_objs = ()\n",
        "\n",
        "for shape in shapes:\n",
        "    print(shape)\n",
        "    tp, tm = get_training_data(os.path.join(input_data_folder, shape))\n",
        "    profile_pngs_objs += tp\n",
        "    midcurve_pngs_objs += tm\n",
        "    print(len(profile_pngs_objs), len(midcurve_pngs_objs))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CapI\n",
            "112 112\n",
            "Iuvw\n",
            "224 224\n",
            "Tuvw\n",
            "336 336\n",
            "Vuvw\n",
            "448 448\n",
            "Sm_n\n",
            "560 560\n",
            "InvV\n",
            "672 672\n",
            "Parl\n",
            "784 784\n",
            "Trap\n",
            "896 896\n",
            "Stik\n",
            "1008 1008\n",
            "Usla\n",
            "1120 1120\n",
            "LapT\n",
            "1232 1232\n",
            "RelY\n",
            "1344 1344\n",
            "T002\n",
            "1456 1456\n",
            "T003\n",
            "1568 1568\n",
            "T004\n",
            "1680 1680\n",
            "T005\n",
            "1792 1792\n",
            "Plus\n",
            "1904 1904\n",
            "SqLu\n",
            "2016 2016\n",
            "Luvw\n",
            "2128 2128\n",
            "L001\n",
            "2240 2240\n",
            "L002\n",
            "2352 2352\n",
            "L003\n",
            "2464 2464\n",
            "T006\n",
            "2576 2576\n",
            "X001\n",
            "2688 2688\n",
            "L004\n",
            "2800 2800\n",
            "Y001\n",
            "2912 2912\n",
            "L100\n",
            "3024 3024\n",
            "Stp1\n",
            "3136 3136\n",
            "I100\n",
            "3248 3248\n",
            "I101\n",
            "3360 3360\n",
            "L005\n",
            "3472 3472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lea0l6OoSS9X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f04d96af-ca53-4c43-c4fc-fc1cb76dc5d9"
      },
      "source": [
        "len(profile_pngs_objs)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3472"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f9N734PSXGH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "25e27abb-c38f-4695-d703-0bb38d8c1bac"
      },
      "source": [
        "profile_pngs_objs[0].shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CON1HkAtWxn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "56aab4b4-9b74-48d7-ae05-0acce840bd18"
      },
      "source": [
        "type(midcurve_pngs_objs)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGcijScSwPr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_results(original_imgs,computed_imgs,n=10):\n",
        "    # n = 10  # how many digits we will display\n",
        "    plt.figure(figsize=(25, 5))\n",
        "    for i in range(n):\n",
        "        # display original\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(original_imgs[i].reshape(imdim, imdim),cmap='gray_r')\n",
        "#         plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "        # display reconstruction\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(computed_imgs[i].reshape(imdim, imdim),cmap='gray_r')\n",
        "#         plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkMvqA_swPr_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "4b72304f-3d88-4df2-ef6c-2215761ed314"
      },
      "source": [
        "plot_results(profile_pngs_objs[2030:2050],midcurve_pngs_objs[2030:2050])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABYEAAAEYCAYAAAAK6TktAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 1800x360 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeLJMAIbwPsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_test_split(profile_pngs_gray_objs, midcurve_pngs_gray_objs, encoding_dim=imdim, input_dim=imdim):\n",
        "\n",
        "    # Training\n",
        "    profile_pngs_flat_objs = [x.reshape(input_dim,input_dim,1) for x in profile_pngs_gray_objs]\n",
        "    midcurve_pngs_flat_objs = [x.reshape(input_dim,input_dim,1) for x in midcurve_pngs_gray_objs]\n",
        "    \n",
        "    profile_pngs_objs = np.array(profile_pngs_flat_objs)\n",
        "    midcurve_pngs_objs= np.array(midcurve_pngs_flat_objs)\n",
        "    \n",
        "    '''\n",
        "    train_size = int(len(profile_pngs_objs)*0.7)\n",
        "    x_train = profile_pngs_objs[:train_size]\n",
        "    y_train = midcurve_pngs_objs[:train_size]\n",
        "    x_test = profile_pngs_objs[train_size:]\n",
        "    y_test = midcurve_pngs_objs[train_size:]\n",
        "    '''\n",
        "    x_train, x_test, y_train, y_test = train_test_split(profile_pngs_objs, midcurve_pngs_objs, \n",
        "                                                        test_size=0.2, random_state=23)\n",
        "    return x_train, x_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsHrNT43wPsG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "35e4c84c-ca2e-4e15-e51f-4542425ba6ab"
      },
      "source": [
        "x_train, x_test, y_train, y_test = get_train_test_split(profile_pngs_objs, midcurve_pngs_objs)\n",
        "\n",
        "print((len(x_train), len(y_train)), (len(x_test), len(y_test)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2777, 2777) (695, 695)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMg0OhMXwPsJ",
        "colab_type": "text"
      },
      "source": [
        "### Auto-encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5GSTXZikY9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Conv2DTranspose\n",
        "\n",
        "class Autoencoder():\n",
        "    def __init__(self):\n",
        "        self.img_rows = imdim\n",
        "        self.img_cols = imdim\n",
        "        self.channels = 1\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        \n",
        "        adam_optimizer = Adam(lr=0.0005)\n",
        "        optimizer = SGD(lr=0.0001, nesterov=False)\n",
        "        \n",
        "        self.autoencoder_model = self.build_model()\n",
        "        #self.autoencoder_model.compile(loss='mean_squared_error', optimizer=RMSprop())\n",
        "        #self.autoencoder_model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "        self.autoencoder_model.compile(loss='mse', metrics=['accuracy'], optimizer=adam_optimizer)\n",
        "        self.autoencoder_model.summary()\n",
        "    \n",
        "    def build_model(self):\n",
        "        input_layer = Input(shape=self.img_shape)\n",
        "                \n",
        "        # Encoder\n",
        "        h = Conv2D(32, (2, 2), activation='relu', padding='same')(input_layer)\n",
        "        #h = MaxPooling2D((2, 2), padding='same')(h)\n",
        "        #h = Conv2D(16, (2, 2), activation='relu', padding='same')(h)\n",
        "        #h = MaxPooling2D((2, 2), padding='same')(h)\n",
        "        \n",
        "        # Decoder\n",
        "        #h = Conv2DTranspose(8, (2, 2), activation='relu', padding='same')(h)\n",
        "        #h = UpSampling2D((2, 2))(h)\n",
        "        h = Conv2DTranspose(32, (2, 2), activation='relu', padding='same')(h)\n",
        "        #h = UpSampling2D((2, 2))(h)\n",
        "        output_layer = Conv2DTranspose(1, (2, 2), activation='relu', padding='same')(h)\n",
        "        \n",
        "        return Model(input_layer, output_layer)\n",
        "    \n",
        "    def train_model(self, x_train, y_train, x_val, y_val, epochs, batch_size=100):\n",
        "        early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                                       min_delta=0,\n",
        "                                       patience=5,\n",
        "                                       verbose=1, \n",
        "                                       mode='auto')\n",
        "        history = self.autoencoder_model.fit(x_train, y_train,\n",
        "                                             batch_size=batch_size,\n",
        "                                             epochs=epochs,\n",
        "                                             validation_data=(x_val, y_val),\n",
        "                                             callbacks=[early_stopping])\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.title('Model loss')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Test'], loc='upper left')\n",
        "        plt.show()\n",
        "    \n",
        "    def eval_model(self, x_test):\n",
        "        preds = self.autoencoder_model.predict(x_test)\n",
        "        return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSsrtRXcKV42",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aacd0552-f1c9-48c6-81d6-b9f602e94e4b"
      },
      "source": [
        "ae = Autoencoder()\n",
        "ae.train_model(x_train, y_train, x_test, y_test, epochs=200, batch_size=300)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 100, 100, 1)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 100, 100, 32)      160       \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_17 (Conv2DT (None, 100, 100, 32)      4128      \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_18 (Conv2DT (None, 100, 100, 1)       129       \n",
            "=================================================================\n",
            "Total params: 4,417\n",
            "Trainable params: 4,417\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 2777 samples, validate on 695 samples\n",
            "Epoch 1/200\n",
            "2777/2777 [==============================] - 4s 1ms/step - loss: 104.2306 - acc: 0.9722 - val_loss: 94.3575 - val_acc: 0.9734\n",
            "Epoch 2/200\n",
            "2777/2777 [==============================] - 2s 859us/step - loss: 99.7834 - acc: 0.9730 - val_loss: 91.4802 - val_acc: 0.9732\n",
            "Epoch 3/200\n",
            "2777/2777 [==============================] - 2s 864us/step - loss: 96.6060 - acc: 0.9720 - val_loss: 89.1772 - val_acc: 0.9725\n",
            "Epoch 4/200\n",
            "2777/2777 [==============================] - 2s 864us/step - loss: 94.1369 - acc: 0.9716 - val_loss: 87.1696 - val_acc: 0.9727\n",
            "Epoch 5/200\n",
            "2777/2777 [==============================] - 2s 860us/step - loss: 92.0100 - acc: 0.9730 - val_loss: 85.5523 - val_acc: 0.9740\n",
            "Epoch 6/200\n",
            "2777/2777 [==============================] - 2s 865us/step - loss: 90.2245 - acc: 0.9731 - val_loss: 84.2145 - val_acc: 0.9737\n",
            "Epoch 7/200\n",
            "2777/2777 [==============================] - 2s 862us/step - loss: 88.7195 - acc: 0.9731 - val_loss: 83.0620 - val_acc: 0.9737\n",
            "Epoch 8/200\n",
            "2777/2777 [==============================] - 2s 868us/step - loss: 87.5048 - acc: 0.9722 - val_loss: 82.1419 - val_acc: 0.9727\n",
            "Epoch 9/200\n",
            "2777/2777 [==============================] - 2s 869us/step - loss: 86.5275 - acc: 0.9720 - val_loss: 81.3979 - val_acc: 0.9733\n",
            "Epoch 10/200\n",
            "2777/2777 [==============================] - 2s 866us/step - loss: 85.7538 - acc: 0.9727 - val_loss: 80.7877 - val_acc: 0.9730\n",
            "Epoch 11/200\n",
            "2777/2777 [==============================] - 2s 868us/step - loss: 85.1017 - acc: 0.9727 - val_loss: 80.2294 - val_acc: 0.9743\n",
            "Epoch 12/200\n",
            "2777/2777 [==============================] - 2s 863us/step - loss: 84.5147 - acc: 0.9733 - val_loss: 79.7180 - val_acc: 0.9740\n",
            "Epoch 13/200\n",
            "2777/2777 [==============================] - 2s 870us/step - loss: 84.0031 - acc: 0.9738 - val_loss: 79.2673 - val_acc: 0.9742\n",
            "Epoch 14/200\n",
            "2777/2777 [==============================] - 2s 875us/step - loss: 83.5556 - acc: 0.9741 - val_loss: 78.8674 - val_acc: 0.9763\n",
            "Epoch 15/200\n",
            "2777/2777 [==============================] - 2s 867us/step - loss: 83.1730 - acc: 0.9750 - val_loss: 78.5074 - val_acc: 0.9757\n",
            "Epoch 16/200\n",
            "2777/2777 [==============================] - 2s 870us/step - loss: 82.7868 - acc: 0.9757 - val_loss: 78.1815 - val_acc: 0.9772\n",
            "Epoch 17/200\n",
            "2777/2777 [==============================] - 2s 868us/step - loss: 82.4483 - acc: 0.9762 - val_loss: 77.8680 - val_acc: 0.9768\n",
            "Epoch 18/200\n",
            "2777/2777 [==============================] - 2s 865us/step - loss: 82.1347 - acc: 0.9763 - val_loss: 77.5469 - val_acc: 0.9775\n",
            "Epoch 19/200\n",
            "2777/2777 [==============================] - 2s 866us/step - loss: 81.8334 - acc: 0.9770 - val_loss: 77.3030 - val_acc: 0.9778\n",
            "Epoch 20/200\n",
            "2777/2777 [==============================] - 2s 867us/step - loss: 81.5706 - acc: 0.9772 - val_loss: 77.0528 - val_acc: 0.9775\n",
            "Epoch 21/200\n",
            "2777/2777 [==============================] - 2s 864us/step - loss: 81.3276 - acc: 0.9771 - val_loss: 76.8560 - val_acc: 0.9780\n",
            "Epoch 22/200\n",
            "2777/2777 [==============================] - 2s 865us/step - loss: 81.1072 - acc: 0.9776 - val_loss: 76.6230 - val_acc: 0.9782\n",
            "Epoch 23/200\n",
            "2777/2777 [==============================] - 2s 869us/step - loss: 80.8896 - acc: 0.9776 - val_loss: 76.4331 - val_acc: 0.9782\n",
            "Epoch 24/200\n",
            "2777/2777 [==============================] - 2s 865us/step - loss: 80.7005 - acc: 0.9778 - val_loss: 76.2576 - val_acc: 0.9785\n",
            "Epoch 25/200\n",
            "2777/2777 [==============================] - 2s 874us/step - loss: 80.5410 - acc: 0.9780 - val_loss: 76.1001 - val_acc: 0.9787\n",
            "Epoch 26/200\n",
            "2777/2777 [==============================] - 2s 869us/step - loss: 80.3683 - acc: 0.9784 - val_loss: 75.9573 - val_acc: 0.9787\n",
            "Epoch 27/200\n",
            "2777/2777 [==============================] - 2s 867us/step - loss: 80.2285 - acc: 0.9783 - val_loss: 75.7939 - val_acc: 0.9789\n",
            "Epoch 28/200\n",
            "2777/2777 [==============================] - 2s 868us/step - loss: 80.0876 - acc: 0.9784 - val_loss: 75.6931 - val_acc: 0.9796\n",
            "Epoch 29/200\n",
            "2777/2777 [==============================] - 2s 867us/step - loss: 79.9649 - acc: 0.9785 - val_loss: 75.5451 - val_acc: 0.9797\n",
            "Epoch 30/200\n",
            "2777/2777 [==============================] - 2s 868us/step - loss: 79.8144 - acc: 0.9786 - val_loss: 75.4374 - val_acc: 0.9791\n",
            "Epoch 31/200\n",
            "2777/2777 [==============================] - 2s 863us/step - loss: 79.6774 - acc: 0.9787 - val_loss: 75.2946 - val_acc: 0.9793\n",
            "Epoch 32/200\n",
            "2777/2777 [==============================] - 2s 865us/step - loss: 79.5578 - acc: 0.9787 - val_loss: 75.1928 - val_acc: 0.9794\n",
            "Epoch 33/200\n",
            "2777/2777 [==============================] - 2s 866us/step - loss: 79.4455 - acc: 0.9788 - val_loss: 75.0912 - val_acc: 0.9792\n",
            "Epoch 34/200\n",
            "2777/2777 [==============================] - 2s 866us/step - loss: 79.3430 - acc: 0.9788 - val_loss: 75.0406 - val_acc: 0.9791\n",
            "Epoch 35/200\n",
            "2777/2777 [==============================] - 2s 867us/step - loss: 79.2464 - acc: 0.9790 - val_loss: 74.8983 - val_acc: 0.9792\n",
            "Epoch 36/200\n",
            "2777/2777 [==============================] - 2s 866us/step - loss: 79.1207 - acc: 0.9790 - val_loss: 74.7726 - val_acc: 0.9796\n",
            "Epoch 37/200\n",
            "2777/2777 [==============================] - 2s 867us/step - loss: 79.0105 - acc: 0.9791 - val_loss: 74.7031 - val_acc: 0.9795\n",
            "Epoch 38/200\n",
            "2777/2777 [==============================] - 2s 863us/step - loss: 78.9240 - acc: 0.9792 - val_loss: 74.5620 - val_acc: 0.9797\n",
            "Epoch 39/200\n",
            "2777/2777 [==============================] - 2s 869us/step - loss: 78.8143 - acc: 0.9791 - val_loss: 74.4595 - val_acc: 0.9802\n",
            "Epoch 40/200\n",
            "2777/2777 [==============================] - 2s 869us/step - loss: 78.7156 - acc: 0.9792 - val_loss: 74.4172 - val_acc: 0.9797\n",
            "Epoch 41/200\n",
            "2777/2777 [==============================] - 2s 868us/step - loss: 78.6176 - acc: 0.9793 - val_loss: 74.2859 - val_acc: 0.9799\n",
            "Epoch 42/200\n",
            "2777/2777 [==============================] - 2s 868us/step - loss: 78.5241 - acc: 0.9793 - val_loss: 74.2256 - val_acc: 0.9803\n",
            "Epoch 43/200\n",
            "2777/2777 [==============================] - 2s 862us/step - loss: 78.4343 - acc: 0.9795 - val_loss: 74.1090 - val_acc: 0.9799\n",
            "Epoch 44/200\n",
            "2777/2777 [==============================] - 2s 868us/step - loss: 78.3429 - acc: 0.9795 - val_loss: 74.0466 - val_acc: 0.9801\n",
            "Epoch 45/200\n",
            "2777/2777 [==============================] - 2s 866us/step - loss: 78.2718 - acc: 0.9795 - val_loss: 74.0303 - val_acc: 0.9798\n",
            "Epoch 46/200\n",
            "2777/2777 [==============================] - 2s 865us/step - loss: 78.2057 - acc: 0.9797 - val_loss: 73.9657 - val_acc: 0.9797\n",
            "Epoch 47/200\n",
            "2777/2777 [==============================] - 2s 869us/step - loss: 78.1488 - acc: 0.9796 - val_loss: 73.9462 - val_acc: 0.9798\n",
            "Epoch 48/200\n",
            "2777/2777 [==============================] - 2s 865us/step - loss: 78.0489 - acc: 0.9798 - val_loss: 73.8435 - val_acc: 0.9798\n",
            "Epoch 49/200\n",
            "2777/2777 [==============================] - 2s 867us/step - loss: 77.9712 - acc: 0.9797 - val_loss: 73.7427 - val_acc: 0.9801\n",
            "Epoch 50/200\n",
            "2777/2777 [==============================] - 2s 869us/step - loss: 77.9029 - acc: 0.9797 - val_loss: 73.6675 - val_acc: 0.9802\n",
            "Epoch 51/200\n",
            "2777/2777 [==============================] - 2s 865us/step - loss: 77.8317 - acc: 0.9797 - val_loss: 73.5486 - val_acc: 0.9805\n",
            "Epoch 52/200\n",
            "2777/2777 [==============================] - 2s 867us/step - loss: 77.8042 - acc: 0.9798 - val_loss: 73.5230 - val_acc: 0.9806\n",
            "Epoch 53/200\n",
            "2777/2777 [==============================] - 2s 864us/step - loss: 77.7395 - acc: 0.9798 - val_loss: 73.4668 - val_acc: 0.9806\n",
            "Epoch 54/200\n",
            "2777/2777 [==============================] - 2s 868us/step - loss: 77.7130 - acc: 0.9799 - val_loss: 73.4517 - val_acc: 0.9805\n",
            "Epoch 55/200\n",
            "2777/2777 [==============================] - 2s 871us/step - loss: 77.6795 - acc: 0.9799 - val_loss: 73.4937 - val_acc: 0.9797\n",
            "Epoch 56/200\n",
            "2777/2777 [==============================] - 2s 863us/step - loss: 77.5916 - acc: 0.9798 - val_loss: 73.4402 - val_acc: 0.9799\n",
            "Epoch 57/200\n",
            "2777/2777 [==============================] - 2s 866us/step - loss: 77.5216 - acc: 0.9799 - val_loss: 73.3748 - val_acc: 0.9800\n",
            "Epoch 58/200\n",
            "2777/2777 [==============================] - 2s 867us/step - loss: 77.4677 - acc: 0.9800 - val_loss: 73.2404 - val_acc: 0.9805\n",
            "Epoch 59/200\n",
            "2777/2777 [==============================] - 2s 863us/step - loss: 77.3997 - acc: 0.9800 - val_loss: 73.2402 - val_acc: 0.9808\n",
            "Epoch 60/200\n",
            "2777/2777 [==============================] - 2s 870us/step - loss: 77.3753 - acc: 0.9801 - val_loss: 73.1536 - val_acc: 0.9807\n",
            "Epoch 61/200\n",
            "2777/2777 [==============================] - 2s 864us/step - loss: 77.3140 - acc: 0.9801 - val_loss: 73.1131 - val_acc: 0.9805\n",
            "Epoch 62/200\n",
            "2777/2777 [==============================] - 2s 867us/step - loss: 77.2637 - acc: 0.9800 - val_loss: 73.0797 - val_acc: 0.9805\n",
            "Epoch 63/200\n",
            "2777/2777 [==============================] - 2s 871us/step - loss: 77.2495 - acc: 0.9801 - val_loss: 73.0254 - val_acc: 0.9809\n",
            "Epoch 64/200\n",
            "2777/2777 [==============================] - 2s 861us/step - loss: 77.1955 - acc: 0.9801 - val_loss: 73.0162 - val_acc: 0.9808\n",
            "Epoch 65/200\n",
            "2777/2777 [==============================] - 2s 865us/step - loss: 77.1525 - acc: 0.9803 - val_loss: 73.0012 - val_acc: 0.9802\n",
            "Epoch 66/200\n",
            "2777/2777 [==============================] - 2s 867us/step - loss: 77.1504 - acc: 0.9801 - val_loss: 72.9373 - val_acc: 0.9809\n",
            "Epoch 67/200\n",
            "2777/2777 [==============================] - 2s 852us/step - loss: 77.0950 - acc: 0.9801 - val_loss: 72.9092 - val_acc: 0.9810\n",
            "Epoch 68/200\n",
            "2777/2777 [==============================] - 2s 846us/step - loss: 77.0790 - acc: 0.9802 - val_loss: 72.8760 - val_acc: 0.9813\n",
            "Epoch 69/200\n",
            "2777/2777 [==============================] - 2s 846us/step - loss: 77.0204 - acc: 0.9804 - val_loss: 72.8215 - val_acc: 0.9808\n",
            "Epoch 70/200\n",
            "2777/2777 [==============================] - 2s 844us/step - loss: 76.9514 - acc: 0.9803 - val_loss: 72.8238 - val_acc: 0.9807\n",
            "Epoch 71/200\n",
            "2777/2777 [==============================] - 2s 843us/step - loss: 76.8958 - acc: 0.9803 - val_loss: 72.7725 - val_acc: 0.9808\n",
            "Epoch 72/200\n",
            "2777/2777 [==============================] - 2s 846us/step - loss: 76.8467 - acc: 0.9804 - val_loss: 72.6966 - val_acc: 0.9808\n",
            "Epoch 73/200\n",
            "2777/2777 [==============================] - 2s 843us/step - loss: 76.8049 - acc: 0.9805 - val_loss: 72.6725 - val_acc: 0.9809\n",
            "Epoch 74/200\n",
            "2777/2777 [==============================] - 2s 845us/step - loss: 76.7663 - acc: 0.9805 - val_loss: 72.6917 - val_acc: 0.9808\n",
            "Epoch 75/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 76.7427 - acc: 0.9805 - val_loss: 72.5903 - val_acc: 0.9810\n",
            "Epoch 76/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 76.6890 - acc: 0.9805 - val_loss: 72.5253 - val_acc: 0.9815\n",
            "Epoch 77/200\n",
            "2777/2777 [==============================] - 2s 844us/step - loss: 76.6827 - acc: 0.9806 - val_loss: 72.5364 - val_acc: 0.9818\n",
            "Epoch 78/200\n",
            "2777/2777 [==============================] - 2s 839us/step - loss: 76.6789 - acc: 0.9806 - val_loss: 72.5168 - val_acc: 0.9816\n",
            "Epoch 79/200\n",
            "2777/2777 [==============================] - 2s 846us/step - loss: 76.6133 - acc: 0.9808 - val_loss: 72.4981 - val_acc: 0.9807\n",
            "Epoch 80/200\n",
            "2777/2777 [==============================] - 2s 841us/step - loss: 76.5744 - acc: 0.9806 - val_loss: 72.4556 - val_acc: 0.9809\n",
            "Epoch 81/200\n",
            "2777/2777 [==============================] - 2s 841us/step - loss: 76.4995 - acc: 0.9808 - val_loss: 72.3773 - val_acc: 0.9817\n",
            "Epoch 82/200\n",
            "2777/2777 [==============================] - 2s 837us/step - loss: 76.4628 - acc: 0.9808 - val_loss: 72.3635 - val_acc: 0.9815\n",
            "Epoch 83/200\n",
            "2777/2777 [==============================] - 2s 841us/step - loss: 76.4256 - acc: 0.9809 - val_loss: 72.3694 - val_acc: 0.9811\n",
            "Epoch 84/200\n",
            "2777/2777 [==============================] - 2s 838us/step - loss: 76.3852 - acc: 0.9809 - val_loss: 72.2576 - val_acc: 0.9812\n",
            "Epoch 85/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 76.3541 - acc: 0.9810 - val_loss: 72.2815 - val_acc: 0.9810\n",
            "Epoch 86/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 76.3190 - acc: 0.9809 - val_loss: 72.1842 - val_acc: 0.9816\n",
            "Epoch 87/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 76.2750 - acc: 0.9811 - val_loss: 72.1324 - val_acc: 0.9818\n",
            "Epoch 88/200\n",
            "2777/2777 [==============================] - 2s 844us/step - loss: 76.2489 - acc: 0.9810 - val_loss: 72.0825 - val_acc: 0.9817\n",
            "Epoch 89/200\n",
            "2777/2777 [==============================] - 2s 838us/step - loss: 76.2159 - acc: 0.9811 - val_loss: 72.2158 - val_acc: 0.9811\n",
            "Epoch 90/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 76.1910 - acc: 0.9811 - val_loss: 72.1014 - val_acc: 0.9814\n",
            "Epoch 91/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 76.1591 - acc: 0.9811 - val_loss: 72.0317 - val_acc: 0.9819\n",
            "Epoch 92/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 76.0861 - acc: 0.9812 - val_loss: 71.9721 - val_acc: 0.9818\n",
            "Epoch 93/200\n",
            "2777/2777 [==============================] - 2s 841us/step - loss: 76.0327 - acc: 0.9813 - val_loss: 71.9558 - val_acc: 0.9813\n",
            "Epoch 94/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 75.9979 - acc: 0.9811 - val_loss: 71.9080 - val_acc: 0.9817\n",
            "Epoch 95/200\n",
            "2777/2777 [==============================] - 2s 841us/step - loss: 75.9568 - acc: 0.9811 - val_loss: 71.9660 - val_acc: 0.9814\n",
            "Epoch 96/200\n",
            "2777/2777 [==============================] - 2s 843us/step - loss: 75.9254 - acc: 0.9812 - val_loss: 71.8481 - val_acc: 0.9815\n",
            "Epoch 97/200\n",
            "2777/2777 [==============================] - 2s 843us/step - loss: 75.8604 - acc: 0.9813 - val_loss: 71.8112 - val_acc: 0.9818\n",
            "Epoch 98/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 75.8182 - acc: 0.9813 - val_loss: 71.7734 - val_acc: 0.9815\n",
            "Epoch 99/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 75.7972 - acc: 0.9812 - val_loss: 71.7061 - val_acc: 0.9818\n",
            "Epoch 100/200\n",
            "2777/2777 [==============================] - 2s 837us/step - loss: 75.7472 - acc: 0.9813 - val_loss: 71.7066 - val_acc: 0.9824\n",
            "Epoch 101/200\n",
            "2777/2777 [==============================] - 2s 844us/step - loss: 75.7424 - acc: 0.9814 - val_loss: 71.6497 - val_acc: 0.9820\n",
            "Epoch 102/200\n",
            "2777/2777 [==============================] - 2s 843us/step - loss: 75.6693 - acc: 0.9814 - val_loss: 71.7299 - val_acc: 0.9814\n",
            "Epoch 103/200\n",
            "2777/2777 [==============================] - 2s 838us/step - loss: 75.6490 - acc: 0.9814 - val_loss: 71.6440 - val_acc: 0.9814\n",
            "Epoch 104/200\n",
            "2777/2777 [==============================] - 2s 837us/step - loss: 75.5766 - acc: 0.9814 - val_loss: 71.5303 - val_acc: 0.9819\n",
            "Epoch 105/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 75.5303 - acc: 0.9814 - val_loss: 71.5324 - val_acc: 0.9817\n",
            "Epoch 106/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 75.5034 - acc: 0.9814 - val_loss: 71.4493 - val_acc: 0.9819\n",
            "Epoch 107/200\n",
            "2777/2777 [==============================] - 2s 841us/step - loss: 75.4374 - acc: 0.9815 - val_loss: 71.4208 - val_acc: 0.9818\n",
            "Epoch 108/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 75.3966 - acc: 0.9815 - val_loss: 71.3868 - val_acc: 0.9818\n",
            "Epoch 109/200\n",
            "2777/2777 [==============================] - 2s 841us/step - loss: 75.3714 - acc: 0.9814 - val_loss: 71.3073 - val_acc: 0.9820\n",
            "Epoch 110/200\n",
            "2777/2777 [==============================] - 2s 837us/step - loss: 75.3010 - acc: 0.9815 - val_loss: 71.2933 - val_acc: 0.9820\n",
            "Epoch 111/200\n",
            "2777/2777 [==============================] - 2s 837us/step - loss: 75.2567 - acc: 0.9816 - val_loss: 71.2620 - val_acc: 0.9819\n",
            "Epoch 112/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 75.2614 - acc: 0.9815 - val_loss: 71.1970 - val_acc: 0.9820\n",
            "Epoch 113/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 75.2004 - acc: 0.9816 - val_loss: 71.1321 - val_acc: 0.9823\n",
            "Epoch 114/200\n",
            "2777/2777 [==============================] - 2s 839us/step - loss: 75.1709 - acc: 0.9817 - val_loss: 71.1366 - val_acc: 0.9820\n",
            "Epoch 115/200\n",
            "2777/2777 [==============================] - 2s 845us/step - loss: 75.1345 - acc: 0.9817 - val_loss: 71.2459 - val_acc: 0.9817\n",
            "Epoch 116/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 75.1418 - acc: 0.9816 - val_loss: 71.0957 - val_acc: 0.9822\n",
            "Epoch 117/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 75.0692 - acc: 0.9818 - val_loss: 71.0347 - val_acc: 0.9824\n",
            "Epoch 118/200\n",
            "2777/2777 [==============================] - 2s 837us/step - loss: 74.9957 - acc: 0.9817 - val_loss: 70.9666 - val_acc: 0.9822\n",
            "Epoch 119/200\n",
            "2777/2777 [==============================] - 2s 848us/step - loss: 74.9762 - acc: 0.9818 - val_loss: 71.0232 - val_acc: 0.9820\n",
            "Epoch 120/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 74.9016 - acc: 0.9817 - val_loss: 70.9336 - val_acc: 0.9821\n",
            "Epoch 121/200\n",
            "2777/2777 [==============================] - 2s 846us/step - loss: 74.8533 - acc: 0.9818 - val_loss: 70.8450 - val_acc: 0.9824\n",
            "Epoch 122/200\n",
            "2777/2777 [==============================] - 2s 844us/step - loss: 74.8075 - acc: 0.9819 - val_loss: 70.8499 - val_acc: 0.9822\n",
            "Epoch 123/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 74.7890 - acc: 0.9818 - val_loss: 70.8065 - val_acc: 0.9828\n",
            "Epoch 124/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 74.7691 - acc: 0.9819 - val_loss: 70.8481 - val_acc: 0.9823\n",
            "Epoch 125/200\n",
            "2777/2777 [==============================] - 2s 843us/step - loss: 74.7309 - acc: 0.9819 - val_loss: 71.1456 - val_acc: 0.9817\n",
            "Epoch 126/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 74.7595 - acc: 0.9819 - val_loss: 70.7160 - val_acc: 0.9824\n",
            "Epoch 127/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 74.6254 - acc: 0.9819 - val_loss: 70.6564 - val_acc: 0.9825\n",
            "Epoch 128/200\n",
            "2777/2777 [==============================] - 2s 844us/step - loss: 74.5789 - acc: 0.9820 - val_loss: 70.6157 - val_acc: 0.9826\n",
            "Epoch 129/200\n",
            "2777/2777 [==============================] - 2s 843us/step - loss: 74.5358 - acc: 0.9820 - val_loss: 70.5859 - val_acc: 0.9828\n",
            "Epoch 130/200\n",
            "2777/2777 [==============================] - 2s 845us/step - loss: 74.5157 - acc: 0.9820 - val_loss: 70.5841 - val_acc: 0.9832\n",
            "Epoch 131/200\n",
            "2777/2777 [==============================] - 2s 845us/step - loss: 74.5098 - acc: 0.9822 - val_loss: 70.5265 - val_acc: 0.9830\n",
            "Epoch 132/200\n",
            "2777/2777 [==============================] - 2s 839us/step - loss: 74.5276 - acc: 0.9824 - val_loss: 70.7528 - val_acc: 0.9820\n",
            "Epoch 133/200\n",
            "2777/2777 [==============================] - 2s 841us/step - loss: 74.5559 - acc: 0.9823 - val_loss: 70.8039 - val_acc: 0.9822\n",
            "Epoch 134/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 74.4496 - acc: 0.9824 - val_loss: 70.4645 - val_acc: 0.9829\n",
            "Epoch 135/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 74.3863 - acc: 0.9825 - val_loss: 70.4108 - val_acc: 0.9831\n",
            "Epoch 136/200\n",
            "2777/2777 [==============================] - 2s 854us/step - loss: 74.2940 - acc: 0.9827 - val_loss: 70.4480 - val_acc: 0.9829\n",
            "Epoch 137/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 74.2569 - acc: 0.9826 - val_loss: 70.3271 - val_acc: 0.9832\n",
            "Epoch 138/200\n",
            "2777/2777 [==============================] - 2s 841us/step - loss: 74.2140 - acc: 0.9827 - val_loss: 70.3395 - val_acc: 0.9830\n",
            "Epoch 139/200\n",
            "2777/2777 [==============================] - 2s 843us/step - loss: 74.1751 - acc: 0.9826 - val_loss: 70.2658 - val_acc: 0.9830\n",
            "Epoch 140/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 74.1593 - acc: 0.9829 - val_loss: 70.3170 - val_acc: 0.9833\n",
            "Epoch 141/200\n",
            "2777/2777 [==============================] - 2s 844us/step - loss: 74.1199 - acc: 0.9828 - val_loss: 70.2118 - val_acc: 0.9834\n",
            "Epoch 142/200\n",
            "2777/2777 [==============================] - 2s 844us/step - loss: 74.1088 - acc: 0.9829 - val_loss: 70.2167 - val_acc: 0.9838\n",
            "Epoch 143/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 74.0764 - acc: 0.9830 - val_loss: 70.1166 - val_acc: 0.9834\n",
            "Epoch 144/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 74.0536 - acc: 0.9830 - val_loss: 70.1818 - val_acc: 0.9838\n",
            "Epoch 145/200\n",
            "2777/2777 [==============================] - 2s 837us/step - loss: 73.9993 - acc: 0.9830 - val_loss: 70.1564 - val_acc: 0.9833\n",
            "Epoch 146/200\n",
            "2777/2777 [==============================] - 2s 838us/step - loss: 73.9678 - acc: 0.9830 - val_loss: 70.1204 - val_acc: 0.9834\n",
            "Epoch 147/200\n",
            "2777/2777 [==============================] - 2s 843us/step - loss: 73.9474 - acc: 0.9830 - val_loss: 70.0559 - val_acc: 0.9839\n",
            "Epoch 148/200\n",
            "2777/2777 [==============================] - 2s 843us/step - loss: 73.9792 - acc: 0.9832 - val_loss: 70.0827 - val_acc: 0.9835\n",
            "Epoch 149/200\n",
            "2777/2777 [==============================] - 2s 844us/step - loss: 73.9286 - acc: 0.9830 - val_loss: 70.1318 - val_acc: 0.9835\n",
            "Epoch 150/200\n",
            "2777/2777 [==============================] - 2s 844us/step - loss: 73.8593 - acc: 0.9832 - val_loss: 69.9590 - val_acc: 0.9836\n",
            "Epoch 151/200\n",
            "2777/2777 [==============================] - 2s 843us/step - loss: 73.8265 - acc: 0.9831 - val_loss: 69.9411 - val_acc: 0.9837\n",
            "Epoch 152/200\n",
            "2777/2777 [==============================] - 2s 838us/step - loss: 73.7782 - acc: 0.9830 - val_loss: 69.9358 - val_acc: 0.9835\n",
            "Epoch 153/200\n",
            "2777/2777 [==============================] - 2s 841us/step - loss: 73.7470 - acc: 0.9831 - val_loss: 69.8967 - val_acc: 0.9836\n",
            "Epoch 154/200\n",
            "2777/2777 [==============================] - 2s 847us/step - loss: 73.7557 - acc: 0.9833 - val_loss: 69.8702 - val_acc: 0.9835\n",
            "Epoch 155/200\n",
            "2777/2777 [==============================] - 2s 844us/step - loss: 73.7032 - acc: 0.9832 - val_loss: 69.9072 - val_acc: 0.9835\n",
            "Epoch 156/200\n",
            "2777/2777 [==============================] - 2s 841us/step - loss: 73.6871 - acc: 0.9831 - val_loss: 69.8853 - val_acc: 0.9836\n",
            "Epoch 157/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 73.6695 - acc: 0.9832 - val_loss: 69.7902 - val_acc: 0.9837\n",
            "Epoch 158/200\n",
            "2777/2777 [==============================] - 2s 844us/step - loss: 73.6689 - acc: 0.9834 - val_loss: 69.7559 - val_acc: 0.9840\n",
            "Epoch 159/200\n",
            "2777/2777 [==============================] - 2s 845us/step - loss: 73.6014 - acc: 0.9832 - val_loss: 69.7882 - val_acc: 0.9841\n",
            "Epoch 160/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 73.5507 - acc: 0.9833 - val_loss: 69.6940 - val_acc: 0.9838\n",
            "Epoch 161/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 73.5237 - acc: 0.9833 - val_loss: 69.7218 - val_acc: 0.9842\n",
            "Epoch 162/200\n",
            "2777/2777 [==============================] - 2s 847us/step - loss: 73.5054 - acc: 0.9833 - val_loss: 69.7224 - val_acc: 0.9838\n",
            "Epoch 163/200\n",
            "2777/2777 [==============================] - 2s 846us/step - loss: 73.4906 - acc: 0.9834 - val_loss: 69.7069 - val_acc: 0.9838\n",
            "Epoch 164/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 73.4708 - acc: 0.9834 - val_loss: 69.7328 - val_acc: 0.9847\n",
            "Epoch 165/200\n",
            "2777/2777 [==============================] - 2s 836us/step - loss: 73.5387 - acc: 0.9837 - val_loss: 69.6055 - val_acc: 0.9839\n",
            "Epoch 166/200\n",
            "2777/2777 [==============================] - 2s 847us/step - loss: 73.4526 - acc: 0.9834 - val_loss: 69.7111 - val_acc: 0.9836\n",
            "Epoch 167/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 73.4089 - acc: 0.9835 - val_loss: 69.6042 - val_acc: 0.9849\n",
            "Epoch 168/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 73.4607 - acc: 0.9838 - val_loss: 69.6945 - val_acc: 0.9855\n",
            "Epoch 169/200\n",
            "2777/2777 [==============================] - 2s 839us/step - loss: 73.5001 - acc: 0.9839 - val_loss: 69.6704 - val_acc: 0.9856\n",
            "Epoch 170/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 73.4132 - acc: 0.9839 - val_loss: 69.5604 - val_acc: 0.9839\n",
            "Epoch 171/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 73.3687 - acc: 0.9838 - val_loss: 69.5958 - val_acc: 0.9839\n",
            "Epoch 172/200\n",
            "2777/2777 [==============================] - 2s 845us/step - loss: 73.3279 - acc: 0.9837 - val_loss: 69.4475 - val_acc: 0.9844\n",
            "Epoch 173/200\n",
            "2777/2777 [==============================] - 2s 843us/step - loss: 73.2568 - acc: 0.9838 - val_loss: 69.4119 - val_acc: 0.9845\n",
            "Epoch 174/200\n",
            "2777/2777 [==============================] - 2s 841us/step - loss: 73.2116 - acc: 0.9838 - val_loss: 69.4191 - val_acc: 0.9841\n",
            "Epoch 175/200\n",
            "2777/2777 [==============================] - 2s 843us/step - loss: 73.1907 - acc: 0.9837 - val_loss: 69.5021 - val_acc: 0.9840\n",
            "Epoch 176/200\n",
            "2777/2777 [==============================] - 2s 844us/step - loss: 73.1463 - acc: 0.9838 - val_loss: 69.4122 - val_acc: 0.9841\n",
            "Epoch 177/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 73.1254 - acc: 0.9838 - val_loss: 69.3176 - val_acc: 0.9843\n",
            "Epoch 178/200\n",
            "2777/2777 [==============================] - 2s 839us/step - loss: 73.1504 - acc: 0.9840 - val_loss: 69.3397 - val_acc: 0.9847\n",
            "Epoch 179/200\n",
            "2777/2777 [==============================] - 2s 841us/step - loss: 73.0922 - acc: 0.9839 - val_loss: 69.3182 - val_acc: 0.9843\n",
            "Epoch 180/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 73.0381 - acc: 0.9840 - val_loss: 69.3392 - val_acc: 0.9844\n",
            "Epoch 181/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 73.0320 - acc: 0.9841 - val_loss: 69.3045 - val_acc: 0.9845\n",
            "Epoch 182/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 73.0063 - acc: 0.9841 - val_loss: 69.3036 - val_acc: 0.9844\n",
            "Epoch 183/200\n",
            "2777/2777 [==============================] - 2s 841us/step - loss: 72.9956 - acc: 0.9841 - val_loss: 69.2586 - val_acc: 0.9846\n",
            "Epoch 184/200\n",
            "2777/2777 [==============================] - 2s 843us/step - loss: 72.9587 - acc: 0.9843 - val_loss: 69.1986 - val_acc: 0.9852\n",
            "Epoch 185/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 72.9238 - acc: 0.9847 - val_loss: 69.2420 - val_acc: 0.9850\n",
            "Epoch 186/200\n",
            "2777/2777 [==============================] - 2s 843us/step - loss: 72.9133 - acc: 0.9847 - val_loss: 69.1499 - val_acc: 0.9854\n",
            "Epoch 187/200\n",
            "2777/2777 [==============================] - 2s 841us/step - loss: 72.9273 - acc: 0.9848 - val_loss: 69.1889 - val_acc: 0.9854\n",
            "Epoch 188/200\n",
            "2777/2777 [==============================] - 2s 845us/step - loss: 72.8560 - acc: 0.9847 - val_loss: 69.0858 - val_acc: 0.9853\n",
            "Epoch 189/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 72.8423 - acc: 0.9848 - val_loss: 69.0842 - val_acc: 0.9851\n",
            "Epoch 190/200\n",
            "2777/2777 [==============================] - 2s 837us/step - loss: 72.8284 - acc: 0.9848 - val_loss: 69.1040 - val_acc: 0.9851\n",
            "Epoch 191/200\n",
            "2777/2777 [==============================] - 2s 846us/step - loss: 72.7922 - acc: 0.9848 - val_loss: 69.0732 - val_acc: 0.9851\n",
            "Epoch 192/200\n",
            "2777/2777 [==============================] - 2s 843us/step - loss: 72.7979 - acc: 0.9848 - val_loss: 69.1161 - val_acc: 0.9860\n",
            "Epoch 193/200\n",
            "2777/2777 [==============================] - 2s 839us/step - loss: 72.7930 - acc: 0.9849 - val_loss: 69.0161 - val_acc: 0.9854\n",
            "Epoch 194/200\n",
            "2777/2777 [==============================] - 2s 842us/step - loss: 72.7433 - acc: 0.9849 - val_loss: 69.1713 - val_acc: 0.9849\n",
            "Epoch 195/200\n",
            "2777/2777 [==============================] - 2s 848us/step - loss: 72.7320 - acc: 0.9849 - val_loss: 68.9868 - val_acc: 0.9852\n",
            "Epoch 196/200\n",
            "2777/2777 [==============================] - 2s 840us/step - loss: 72.7051 - acc: 0.9849 - val_loss: 68.9871 - val_acc: 0.9856\n",
            "Epoch 197/200\n",
            "2777/2777 [==============================] - 2s 844us/step - loss: 72.6561 - acc: 0.9850 - val_loss: 68.9145 - val_acc: 0.9858\n",
            "Epoch 198/200\n",
            "2777/2777 [==============================] - 2s 846us/step - loss: 72.6338 - acc: 0.9851 - val_loss: 68.9006 - val_acc: 0.9852\n",
            "Epoch 199/200\n",
            "2777/2777 [==============================] - 2s 837us/step - loss: 72.5971 - acc: 0.9851 - val_loss: 68.9194 - val_acc: 0.9854\n",
            "Epoch 200/200\n",
            "2777/2777 [==============================] - 2s 837us/step - loss: 72.5714 - acc: 0.9850 - val_loss: 68.9131 - val_acc: 0.9858\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B9wjkHmKdrs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "7e501432-a890-4de7-c1f8-765444e623a1"
      },
      "source": [
        "# evaluation\n",
        "\n",
        "n = 10  # for 10 random indices\n",
        "index = np.random.choice(x_test.shape[0], n, replace=False)\n",
        "\n",
        "x_eval = x_test[index]\n",
        "print(\"Number of samples to evaluate: \", len(x_eval))\n",
        "print(\"Samples to evaluate: \", index)\n",
        "\n",
        "#encoded_imgs = ae.eval_model(x_test)\n",
        "encoded_imgs = ae.eval_model(x_eval)\n",
        "decoded_imgs = ae.eval_model(encoded_imgs)\n",
        "\n",
        "plot_results(x_eval, decoded_imgs)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples to evaluate:  10\n",
            "Samples to evaluate:  [ 69  18 248 448 112 599 403 100 282 553]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABYEAAAEYCAYAAAAK6TktAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/g85+9IcMqNJqAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1800x360 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMR2KgXaKZqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
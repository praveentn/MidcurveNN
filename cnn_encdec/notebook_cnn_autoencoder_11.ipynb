{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "notebook_cnn_autoencoder_11.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveentn/MidcurveNN/blob/master/cnn_encdec/notebook_cnn_autoencoder_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQVJL5mHwPrl",
        "colab_type": "text"
      },
      "source": [
        "# CNN ENC-DEC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxYRQhxBxAbv",
        "colab_type": "code",
        "outputId": "94334a41-cd5a-4269-90c4-42dde150183c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# mount google drive & set working directory\n",
        "# requires auth (click on url & copy token into text box when prompted)\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "import os\n",
        "print(os.getcwd())\n",
        "\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks/MidcurveNN')\n",
        "!pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/Colab Notebooks/MidcurveNN\n",
            "/content/gdrive/My Drive/Colab Notebooks/MidcurveNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDHgEuJBwPrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# !pip install tensorflow-gpu==2.0.0-alpha0\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import PIL\n",
        "import json\n",
        "import time\n",
        "\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "from keras import regularizers, optimizers\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Conv2D, UpSampling2D, Reshape, Flatten\n",
        "from keras.layers import GlobalMaxPooling2D, AveragePooling2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "from random import shuffle\n",
        "\n",
        "import numpy as np\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import matplotlib\n",
        "# matplotlib.use('TKAgg')\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evVd6EPUwPrs",
        "colab_type": "code",
        "outputId": "1b3319f6-7f2b-4539-c749-02e66e93811c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# working directory\n",
        "wdir = os.getcwd()\n",
        "wdir"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/Colab Notebooks/MidcurveNN'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxFdYYywwPrx",
        "colab_type": "code",
        "outputId": "41cad983-682a-4f5a-b66c-7b9ee6ab09c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# _URL = 'https://drive.google.com/uc?export=download&id=16rqDFLO__WySSQGlAht0FEj2uJZg4M9M'\n",
        "\n",
        "# path_to_zip = tf.keras.utils.get_file('input.zip',\n",
        "#                                       origin=_URL,\n",
        "#                                       extract=True)\n",
        "\n",
        "# input_data_folder = os.path.join(os.path.dirname(path_to_zip), 'input')\n",
        "input_data_folder = wdir + \"/data/input\"\n",
        "input_data_folder = wdir + \"/data/images\"\n",
        "print(\"input data dir: \", input_data_folder)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input data dir:  /content/gdrive/My Drive/Colab Notebooks/MidcurveNN/data/images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geTVDZfzPY-u",
        "colab_type": "code",
        "outputId": "7c7349f4-a426-4506-a7dd-c3df81451017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import glob\n",
        "\n",
        "image_paths = glob.glob(input_data_folder + '/**/*.png', recursive=True)\n",
        "images = [os.path.basename(img_path) for img_path in image_paths]\n",
        "\n",
        "print(len(images))\n",
        "\n",
        "#images = os.listdir(input_data_folder)\n",
        "images[99]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5376\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'CapI_Midcurve_mirrored_0_translated_10_-20.png'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNZW79Q1URmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image dimension\n",
        "imdim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjdmJfpRwPr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_input_image_pairs(datafolder=input_data_folder):\n",
        "    profile_pngs = []\n",
        "    midcurve_pngs = []\n",
        "    for file in os.listdir(datafolder):\n",
        "        fullpath = os.path.join(datafolder, file)\n",
        "        if os.path.isdir(fullpath):\n",
        "            continue\n",
        "        if file.endswith(\".png\"):\n",
        "            if file.find(\"Profile\") != -1:\n",
        "                profile_pngs.append(fullpath)\n",
        "            if file.find(\"Midcurve\") != -1:\n",
        "                midcurve_pngs.append(fullpath)\n",
        "    profile_pngs = sorted(profile_pngs)\n",
        "    midcurve_pngs = sorted(midcurve_pngs)\n",
        "    return profile_pngs,midcurve_pngs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rim24hWkwPr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_training_data(datafolder=input_data_folder):\n",
        "    profile_pngs,midcurve_pngs = read_input_image_pairs(datafolder)\n",
        "    \n",
        "    profile_pngs_objs = [img_to_array(load_img(f, color_mode='rgba', target_size=(imdim, imdim))) for f in profile_pngs ]\n",
        "    midcurve_pngs_objs = [img_to_array(load_img(f, color_mode='rgba', target_size=(imdim, imdim))) for f in midcurve_pngs]\n",
        "\n",
        "#     profile_pngs_objs = np.array([x.reshape((1,) + x.shape) for x in profile_pngs_objs])\n",
        "#     midcurve_pngs_objs = np.array([x.reshape((1,) + x.shape) for x in midcurve_pngs_objs])\n",
        "\n",
        "    profile_pngs_gray_objs = [x[:,:,3] for x in profile_pngs_objs]\n",
        "    midcurve_pngs_gray_objs =[x[:,:,3] for x in midcurve_pngs_objs]\n",
        "    \n",
        "#     profile_pngs_gray_objs = [np.where(x>128, 0, 1) for x in profile_pngs_gray_objs]\n",
        "#     midcurve_pngs_gray_objs =[np.where(x>128, 0, 1) for x in midcurve_pngs_gray_objs]\n",
        "        \n",
        "    # shufle them\n",
        "    zipped_profiles_midcurves = [(p,m) for p,m in zip(profile_pngs_gray_objs,midcurve_pngs_gray_objs)]\n",
        "    shuffle(zipped_profiles_midcurves)\n",
        "    profile_pngs_gray_objs, midcurve_pngs_gray_objs = zip(*zipped_profiles_midcurves)\n",
        "    \n",
        "    return profile_pngs_gray_objs, midcurve_pngs_gray_objs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEfyWOYCiYxD",
        "colab_type": "code",
        "outputId": "ed2f67af-a907-413c-a4a6-024bdeb4c4ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "shapes = os.listdir('/content/gdrive/My Drive/Colab Notebooks/MidcurveNN/data/images')\n",
        "shapes"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CapI',\n",
              " 'Iuvw',\n",
              " 'Tuvw',\n",
              " 'Vuvw',\n",
              " 'Sm_n',\n",
              " 'InvV',\n",
              " 'Parl',\n",
              " 'Trap',\n",
              " 'Stik',\n",
              " 'Usla',\n",
              " 'LapT',\n",
              " 'RelY',\n",
              " 'T002',\n",
              " 'T003',\n",
              " 'T004',\n",
              " 'T005',\n",
              " 'Plus',\n",
              " 'SqLu',\n",
              " 'Luvw',\n",
              " 'L001',\n",
              " 'L002',\n",
              " 'L003',\n",
              " 'T006',\n",
              " 'X001']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP3POQEVtlck",
        "colab_type": "code",
        "outputId": "1a24e7a7-d39e-46d3-9bdb-343515e0ab87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "profile_pngs_objs = ()\n",
        "midcurve_pngs_objs = ()\n",
        "\n",
        "for shape in shapes:\n",
        "    print(shape)\n",
        "    tp, tm = get_training_data(os.path.join(input_data_folder, shape))\n",
        "    profile_pngs_objs += tp\n",
        "    midcurve_pngs_objs += tm\n",
        "    print(len(profile_pngs_objs), len(midcurve_pngs_objs))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CapI\n",
            "112 112\n",
            "Iuvw\n",
            "224 224\n",
            "Tuvw\n",
            "336 336\n",
            "Vuvw\n",
            "448 448\n",
            "Sm_n\n",
            "560 560\n",
            "InvV\n",
            "672 672\n",
            "Parl\n",
            "784 784\n",
            "Trap\n",
            "896 896\n",
            "Stik\n",
            "1008 1008\n",
            "Usla\n",
            "1120 1120\n",
            "LapT\n",
            "1232 1232\n",
            "RelY\n",
            "1344 1344\n",
            "T002\n",
            "1456 1456\n",
            "T003\n",
            "1568 1568\n",
            "T004\n",
            "1680 1680\n",
            "T005\n",
            "1792 1792\n",
            "Plus\n",
            "1904 1904\n",
            "SqLu\n",
            "2016 2016\n",
            "Luvw\n",
            "2128 2128\n",
            "L001\n",
            "2240 2240\n",
            "L002\n",
            "2352 2352\n",
            "L003\n",
            "2464 2464\n",
            "T006\n",
            "2576 2576\n",
            "X001\n",
            "2688 2688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lea0l6OoSS9X",
        "colab_type": "code",
        "outputId": "ef73e584-6539-4f9c-82bd-d2020a464a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(profile_pngs_objs)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2688"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f9N734PSXGH",
        "colab_type": "code",
        "outputId": "cba80024-e90a-4c7a-c015-2a724f8b3d8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "profile_pngs_objs[0].shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CON1HkAtWxn",
        "colab_type": "code",
        "outputId": "5626b288-d45d-48a3-af3f-4d6b750832f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "type(midcurve_pngs_objs)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGcijScSwPr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_results(original_imgs,computed_imgs,n=10):\n",
        "    # n = 10  # how many digits we will display\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(n):\n",
        "        # display original\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(original_imgs[i].reshape(imdim, imdim),cmap='gray_r')\n",
        "#         plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "        # display reconstruction\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(computed_imgs[i].reshape(imdim, imdim),cmap='gray_r')\n",
        "#         plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkMvqA_swPr_",
        "colab_type": "code",
        "outputId": "2527ca6c-bc4d-4460-d8ac-3135b7c0aa41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "plot_results(profile_pngs_objs[2030:2050],midcurve_pngs_objs[2030:2050])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAADjCAYAAADdR/IFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeLJMAIbwPsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_test_split(profile_pngs_gray_objs, midcurve_pngs_gray_objs, encoding_dim=imdim, input_dim=imdim):\n",
        "\n",
        "    # Training\n",
        "    profile_pngs_flat_objs = [x.reshape(input_dim,input_dim,1) for x in profile_pngs_gray_objs]\n",
        "    midcurve_pngs_flat_objs = [x.reshape(input_dim,input_dim,1) for x in midcurve_pngs_gray_objs]\n",
        "    \n",
        "    profile_pngs_objs = np.array(profile_pngs_flat_objs)\n",
        "    midcurve_pngs_objs= np.array(midcurve_pngs_flat_objs)\n",
        "    \n",
        "    '''\n",
        "    train_size = int(len(profile_pngs_objs)*0.7)\n",
        "    x_train = profile_pngs_objs[:train_size]\n",
        "    y_train = midcurve_pngs_objs[:train_size]\n",
        "    x_test = profile_pngs_objs[train_size:]\n",
        "    y_test = midcurve_pngs_objs[train_size:]\n",
        "    '''\n",
        "    x_train, x_test, y_train, y_test = train_test_split(profile_pngs_objs, midcurve_pngs_objs, \n",
        "                                                        test_size=0.2, random_state=23)\n",
        "    return x_train, x_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsHrNT43wPsG",
        "colab_type": "code",
        "outputId": "35c6c7b9-aacc-4e60-ffae-cd4c2f8c1494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train, x_test, y_train, y_test = get_train_test_split(profile_pngs_objs, midcurve_pngs_objs)\n",
        "\n",
        "print((len(x_train), len(y_train)), (len(x_test), len(y_test)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2150, 2150) (538, 538)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMg0OhMXwPsJ",
        "colab_type": "text"
      },
      "source": [
        "### Auto-encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnGlEsrp5G9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Autoencoder():\n",
        "    def __init__(self):\n",
        "        self.img_rows = imdim\n",
        "        self.img_cols = imdim\n",
        "        self.channels = 1\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        \n",
        "        adam_optimizer = Adam(lr=0.0005)\n",
        "        optimizer = SGD(lr=0.0001, nesterov=False)\n",
        "        \n",
        "        self.autoencoder_model = self.build_model()\n",
        "        #self.autoencoder_model.compile(loss='mean_squared_error', optimizer=RMSprop())\n",
        "        #self.autoencoder_model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "        self.autoencoder_model.compile(loss='mse', metrics=['accuracy'], optimizer=adam_optimizer)\n",
        "        self.autoencoder_model.summary()\n",
        "    \n",
        "    def build_model(self):\n",
        "        input_layer = Input(shape=self.img_shape)\n",
        "        \n",
        "        '''\n",
        "        # encoder\n",
        "        x = Conv2D(32, (3,3), activation='relu', padding='same')(input_layer) # 28 x 28 x 32\n",
        "        x = MaxPooling2D(pool_size=(2,2))(x) # 14 x 14 x 32\n",
        "        x = Conv2D(64, (3,3), activation='relu', padding='same')(x)# 14 x 14 x 64\n",
        "        x = MaxPooling2D(pool_size=(2,2))(x) # 7 x 7 x 64\n",
        "        x = Conv2D(128, (3,3), activation='relu', padding='same')(x) # 7 x 7 x 128\n",
        "\n",
        "        # decoder\n",
        "        x = Conv2D(128, (3,3), activation='relu', padding='same')(x) # 7 x 7 x 128\n",
        "        x = UpSampling2D((2,2))(x) # 14 x 14 x 128\n",
        "        x = Conv2D(64, (3,3), activation='relu', padding='same')(x)# 14 x 14 x 64\n",
        "        x = UpSampling2D((2,2))(x) # 28 x 28 x 64\n",
        "        output_layer = Conv2D(1, (3,3), activation='sigmoid', padding='same')(x) # 28 x 28 x 1\n",
        "        '''\n",
        "        \n",
        "        # encoder\n",
        "        x = Conv2D(8, (3,3), activation='relu', padding='same')(input_layer)\n",
        "        x = MaxPooling2D(pool_size=(2,2))(x) # 14 x 14 x 32\n",
        "        #x = GlobalMaxPooling2D()(x) # 14 x 14 x 32\n",
        "        x = Conv2D(16, (3,3), activation='relu', padding='same')(x)\n",
        "        x = MaxPooling2D(pool_size=(2,2))(x) # 7 x 7 x 64\n",
        "        #x = GlobalMaxPooling2D()(x) # 7 x 7 x 64\n",
        "        x = Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
        "\n",
        "        # decoder\n",
        "        x = Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
        "        x = UpSampling2D((2,2))(x) # 14 x 14 x 128\n",
        "        x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
        "        x = UpSampling2D((2,2))(x) # 28 x 28 x 64\n",
        "        #output_layer = Conv2D(1, (3,3), activation='sigmoid', padding='same')(x)\n",
        "        output_layer = Conv2D(1, (3,3), activation='relu', padding='same')(x)\n",
        "        \n",
        "        \n",
        "        return Model(input_layer, output_layer)\n",
        "    \n",
        "    def train_model(self, x_train, y_train, x_val, y_val, epochs, batch_size=100):\n",
        "        early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                                       min_delta=0,\n",
        "                                       patience=5,\n",
        "                                       verbose=1, \n",
        "                                       mode='auto')\n",
        "        history = self.autoencoder_model.fit(x_train, y_train,\n",
        "                                             batch_size=batch_size,\n",
        "                                             epochs=epochs,\n",
        "                                             validation_data=(x_val, y_val),\n",
        "                                             callbacks=[early_stopping])\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.title('Model loss')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Test'], loc='upper left')\n",
        "        plt.show()\n",
        "    \n",
        "    def eval_model(self, x_test):\n",
        "        preds = self.autoencoder_model.predict(x_test)\n",
        "        return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS9oXJ9e5KrT",
        "colab_type": "code",
        "outputId": "f9153f9b-650c-4b6f-f851-11765f37c3ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "'''\n",
        "x_train_reshaped = x_train\n",
        "x_test_reshaped = x_test\n",
        "\n",
        "\n",
        "noise_factor = 0.01 \n",
        "x_train_noisy = x_train_reshaped + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train_reshaped.shape) \n",
        "x_test_noisy = x_test_reshaped + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test_reshaped.shape) \n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.) \n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
        "'''\n",
        "\n",
        "ae = Autoencoder()\n",
        "#ae.train_model(x_train_noisy, y_train, x_test_noisy, y_test, epochs=50, batch_size=32)\n",
        "ae.train_model(x_train, y_train, x_test, y_test, epochs=200, batch_size=100)\n",
        "\n",
        "#encoded_imgs = ae.eval_model(x_test)\n",
        "#decoded_imgs = ae.eval_model(encoded_imgs)\n",
        "\n",
        "#plot_results(x_test, decoded_imgs)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         (None, 100, 100, 1)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 100, 100, 8)       80        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 50, 50, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 50, 50, 16)        1168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 25, 25, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 25, 25, 32)        4640      \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 25, 25, 32)        9248      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_9 (UpSampling2 (None, 50, 50, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 50, 50, 64)        18496     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_10 (UpSampling (None, 100, 100, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 100, 100, 1)       577       \n",
            "=================================================================\n",
            "Total params: 34,209\n",
            "Trainable params: 34,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 2150 samples, validate on 538 samples\n",
            "Epoch 1/200\n",
            "2150/2150 [==============================] - 4s 2ms/step - loss: 88.8663 - acc: 0.9504 - val_loss: 75.6758 - val_acc: 0.9837\n",
            "Epoch 2/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 77.5236 - acc: 0.9850 - val_loss: 70.6188 - val_acc: 0.9877\n",
            "Epoch 3/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 72.0536 - acc: 0.9868 - val_loss: 65.4399 - val_acc: 0.9879\n",
            "Epoch 4/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 66.6040 - acc: 0.9873 - val_loss: 60.6351 - val_acc: 0.9880\n",
            "Epoch 5/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 61.8425 - acc: 0.9877 - val_loss: 56.6272 - val_acc: 0.9881\n",
            "Epoch 6/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 57.8552 - acc: 0.9880 - val_loss: 54.6237 - val_acc: 0.9897\n",
            "Epoch 7/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 54.8172 - acc: 0.9886 - val_loss: 50.8467 - val_acc: 0.9887\n",
            "Epoch 8/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 51.5648 - acc: 0.9887 - val_loss: 48.7521 - val_acc: 0.9890\n",
            "Epoch 9/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 49.3222 - acc: 0.9894 - val_loss: 46.8686 - val_acc: 0.9901\n",
            "Epoch 10/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 47.5469 - acc: 0.9896 - val_loss: 45.3944 - val_acc: 0.9908\n",
            "Epoch 11/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 44.9375 - acc: 0.9902 - val_loss: 43.9148 - val_acc: 0.9902\n",
            "Epoch 12/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 43.2534 - acc: 0.9906 - val_loss: 42.9054 - val_acc: 0.9905\n",
            "Epoch 13/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 41.9309 - acc: 0.9909 - val_loss: 41.4783 - val_acc: 0.9909\n",
            "Epoch 14/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 40.2070 - acc: 0.9913 - val_loss: 39.8509 - val_acc: 0.9919\n",
            "Epoch 15/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 38.9773 - acc: 0.9916 - val_loss: 39.0007 - val_acc: 0.9917\n",
            "Epoch 16/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 38.1242 - acc: 0.9919 - val_loss: 38.0561 - val_acc: 0.9920\n",
            "Epoch 17/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 37.1802 - acc: 0.9920 - val_loss: 37.4968 - val_acc: 0.9924\n",
            "Epoch 18/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 36.3965 - acc: 0.9920 - val_loss: 36.6076 - val_acc: 0.9923\n",
            "Epoch 19/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 35.9015 - acc: 0.9921 - val_loss: 36.4191 - val_acc: 0.9928\n",
            "Epoch 20/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 35.3711 - acc: 0.9922 - val_loss: 36.1090 - val_acc: 0.9930\n",
            "Epoch 21/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 34.4904 - acc: 0.9923 - val_loss: 35.2019 - val_acc: 0.9922\n",
            "Epoch 22/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 33.8062 - acc: 0.9924 - val_loss: 34.6206 - val_acc: 0.9928\n",
            "Epoch 23/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 33.2955 - acc: 0.9925 - val_loss: 34.0443 - val_acc: 0.9927\n",
            "Epoch 24/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 32.7879 - acc: 0.9925 - val_loss: 33.6250 - val_acc: 0.9927\n",
            "Epoch 25/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 32.4247 - acc: 0.9926 - val_loss: 33.2892 - val_acc: 0.9926\n",
            "Epoch 26/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 31.9528 - acc: 0.9926 - val_loss: 32.9960 - val_acc: 0.9932\n",
            "Epoch 27/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 31.3841 - acc: 0.9928 - val_loss: 32.6637 - val_acc: 0.9927\n",
            "Epoch 28/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 31.0435 - acc: 0.9928 - val_loss: 32.2346 - val_acc: 0.9929\n",
            "Epoch 29/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 30.6128 - acc: 0.9928 - val_loss: 31.9153 - val_acc: 0.9930\n",
            "Epoch 30/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 30.2806 - acc: 0.9929 - val_loss: 31.8245 - val_acc: 0.9929\n",
            "Epoch 31/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 30.0377 - acc: 0.9929 - val_loss: 31.2981 - val_acc: 0.9931\n",
            "Epoch 32/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 29.6785 - acc: 0.9930 - val_loss: 32.0661 - val_acc: 0.9926\n",
            "Epoch 33/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 29.5354 - acc: 0.9930 - val_loss: 30.7559 - val_acc: 0.9933\n",
            "Epoch 34/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 28.9769 - acc: 0.9931 - val_loss: 30.4536 - val_acc: 0.9932\n",
            "Epoch 35/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 28.6213 - acc: 0.9931 - val_loss: 30.3914 - val_acc: 0.9930\n",
            "Epoch 36/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 28.5352 - acc: 0.9931 - val_loss: 30.2679 - val_acc: 0.9930\n",
            "Epoch 37/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 28.1845 - acc: 0.9932 - val_loss: 29.7947 - val_acc: 0.9934\n",
            "Epoch 38/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 27.9917 - acc: 0.9932 - val_loss: 29.5263 - val_acc: 0.9933\n",
            "Epoch 39/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 27.6120 - acc: 0.9932 - val_loss: 29.4392 - val_acc: 0.9935\n",
            "Epoch 40/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 27.2825 - acc: 0.9932 - val_loss: 29.4647 - val_acc: 0.9931\n",
            "Epoch 41/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 27.0582 - acc: 0.9933 - val_loss: 29.3174 - val_acc: 0.9937\n",
            "Epoch 42/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 27.0209 - acc: 0.9933 - val_loss: 29.1949 - val_acc: 0.9930\n",
            "Epoch 43/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 26.7893 - acc: 0.9933 - val_loss: 28.6045 - val_acc: 0.9937\n",
            "Epoch 44/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 26.3264 - acc: 0.9934 - val_loss: 28.3084 - val_acc: 0.9934\n",
            "Epoch 45/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 26.0605 - acc: 0.9934 - val_loss: 28.4445 - val_acc: 0.9933\n",
            "Epoch 46/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 25.9060 - acc: 0.9934 - val_loss: 28.1987 - val_acc: 0.9938\n",
            "Epoch 47/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 25.7544 - acc: 0.9934 - val_loss: 28.0899 - val_acc: 0.9937\n",
            "Epoch 48/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 25.4525 - acc: 0.9935 - val_loss: 27.6265 - val_acc: 0.9937\n",
            "Epoch 49/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 25.1880 - acc: 0.9935 - val_loss: 27.3889 - val_acc: 0.9937\n",
            "Epoch 50/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 24.9825 - acc: 0.9935 - val_loss: 27.4937 - val_acc: 0.9937\n",
            "Epoch 51/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 24.9422 - acc: 0.9936 - val_loss: 27.0240 - val_acc: 0.9935\n",
            "Epoch 52/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 24.8900 - acc: 0.9935 - val_loss: 27.1478 - val_acc: 0.9939\n",
            "Epoch 53/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 24.7276 - acc: 0.9935 - val_loss: 26.7498 - val_acc: 0.9939\n",
            "Epoch 54/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 24.2991 - acc: 0.9936 - val_loss: 27.0649 - val_acc: 0.9935\n",
            "Epoch 55/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 24.2412 - acc: 0.9936 - val_loss: 26.6931 - val_acc: 0.9936\n",
            "Epoch 56/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 24.0307 - acc: 0.9936 - val_loss: 26.4246 - val_acc: 0.9936\n",
            "Epoch 57/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 23.7659 - acc: 0.9937 - val_loss: 26.2983 - val_acc: 0.9940\n",
            "Epoch 58/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 23.6799 - acc: 0.9937 - val_loss: 26.2046 - val_acc: 0.9938\n",
            "Epoch 59/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 23.4869 - acc: 0.9937 - val_loss: 25.9791 - val_acc: 0.9939\n",
            "Epoch 60/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 23.2088 - acc: 0.9937 - val_loss: 25.8634 - val_acc: 0.9939\n",
            "Epoch 61/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 23.0892 - acc: 0.9937 - val_loss: 25.7574 - val_acc: 0.9941\n",
            "Epoch 62/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 23.0653 - acc: 0.9938 - val_loss: 25.5590 - val_acc: 0.9940\n",
            "Epoch 63/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 22.7544 - acc: 0.9938 - val_loss: 25.5239 - val_acc: 0.9940\n",
            "Epoch 64/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 22.6098 - acc: 0.9938 - val_loss: 25.2103 - val_acc: 0.9940\n",
            "Epoch 65/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 22.4554 - acc: 0.9938 - val_loss: 25.3795 - val_acc: 0.9937\n",
            "Epoch 66/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 22.6171 - acc: 0.9938 - val_loss: 25.3754 - val_acc: 0.9939\n",
            "Epoch 67/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 22.2283 - acc: 0.9938 - val_loss: 24.9015 - val_acc: 0.9941\n",
            "Epoch 68/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 22.0447 - acc: 0.9939 - val_loss: 24.8145 - val_acc: 0.9939\n",
            "Epoch 69/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 21.9901 - acc: 0.9939 - val_loss: 24.8063 - val_acc: 0.9939\n",
            "Epoch 70/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 21.7768 - acc: 0.9939 - val_loss: 24.5901 - val_acc: 0.9941\n",
            "Epoch 71/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 21.7965 - acc: 0.9939 - val_loss: 24.5910 - val_acc: 0.9939\n",
            "Epoch 72/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 21.5417 - acc: 0.9939 - val_loss: 24.8543 - val_acc: 0.9938\n",
            "Epoch 73/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 21.6178 - acc: 0.9940 - val_loss: 24.6110 - val_acc: 0.9941\n",
            "Epoch 74/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 21.2505 - acc: 0.9940 - val_loss: 24.3395 - val_acc: 0.9940\n",
            "Epoch 75/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 21.1883 - acc: 0.9940 - val_loss: 24.3404 - val_acc: 0.9944\n",
            "Epoch 76/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 21.0911 - acc: 0.9940 - val_loss: 24.2530 - val_acc: 0.9939\n",
            "Epoch 77/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 20.9890 - acc: 0.9940 - val_loss: 23.9558 - val_acc: 0.9942\n",
            "Epoch 78/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 20.7443 - acc: 0.9941 - val_loss: 23.8485 - val_acc: 0.9942\n",
            "Epoch 79/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 20.8449 - acc: 0.9941 - val_loss: 24.0246 - val_acc: 0.9939\n",
            "Epoch 80/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 20.5428 - acc: 0.9941 - val_loss: 23.6861 - val_acc: 0.9941\n",
            "Epoch 81/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 20.5396 - acc: 0.9941 - val_loss: 23.6041 - val_acc: 0.9942\n",
            "Epoch 82/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 20.3287 - acc: 0.9941 - val_loss: 23.7095 - val_acc: 0.9942\n",
            "Epoch 83/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 20.2618 - acc: 0.9941 - val_loss: 23.4327 - val_acc: 0.9942\n",
            "Epoch 84/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 20.1572 - acc: 0.9941 - val_loss: 23.3767 - val_acc: 0.9943\n",
            "Epoch 85/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 20.2112 - acc: 0.9941 - val_loss: 23.5097 - val_acc: 0.9941\n",
            "Epoch 86/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 19.9537 - acc: 0.9942 - val_loss: 23.3395 - val_acc: 0.9941\n",
            "Epoch 87/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 20.1967 - acc: 0.9941 - val_loss: 23.3314 - val_acc: 0.9942\n",
            "Epoch 88/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 19.9466 - acc: 0.9942 - val_loss: 23.1039 - val_acc: 0.9943\n",
            "Epoch 89/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 19.7110 - acc: 0.9942 - val_loss: 23.1655 - val_acc: 0.9942\n",
            "Epoch 90/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 19.5706 - acc: 0.9942 - val_loss: 23.2187 - val_acc: 0.9945\n",
            "Epoch 91/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 19.4660 - acc: 0.9942 - val_loss: 22.9021 - val_acc: 0.9944\n",
            "Epoch 92/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 19.4502 - acc: 0.9942 - val_loss: 23.1971 - val_acc: 0.9941\n",
            "Epoch 93/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 19.4291 - acc: 0.9942 - val_loss: 23.1929 - val_acc: 0.9946\n",
            "Epoch 94/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 19.1609 - acc: 0.9942 - val_loss: 22.8759 - val_acc: 0.9942\n",
            "Epoch 95/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 19.1600 - acc: 0.9942 - val_loss: 22.6926 - val_acc: 0.9944\n",
            "Epoch 96/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 19.0520 - acc: 0.9942 - val_loss: 22.6008 - val_acc: 0.9944\n",
            "Epoch 97/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 18.8824 - acc: 0.9943 - val_loss: 22.5301 - val_acc: 0.9944\n",
            "Epoch 98/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 18.8990 - acc: 0.9943 - val_loss: 22.6573 - val_acc: 0.9945\n",
            "Epoch 99/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 18.8683 - acc: 0.9943 - val_loss: 22.9596 - val_acc: 0.9941\n",
            "Epoch 100/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 18.8599 - acc: 0.9943 - val_loss: 22.7734 - val_acc: 0.9946\n",
            "Epoch 101/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 18.6742 - acc: 0.9943 - val_loss: 22.3910 - val_acc: 0.9943\n",
            "Epoch 102/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 18.4839 - acc: 0.9943 - val_loss: 22.3136 - val_acc: 0.9943\n",
            "Epoch 103/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 18.4876 - acc: 0.9943 - val_loss: 22.4149 - val_acc: 0.9945\n",
            "Epoch 104/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 18.4296 - acc: 0.9943 - val_loss: 22.1460 - val_acc: 0.9943\n",
            "Epoch 105/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 18.3934 - acc: 0.9943 - val_loss: 22.6922 - val_acc: 0.9946\n",
            "Epoch 106/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 18.5414 - acc: 0.9943 - val_loss: 22.2005 - val_acc: 0.9944\n",
            "Epoch 107/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 18.1745 - acc: 0.9943 - val_loss: 21.9251 - val_acc: 0.9944\n",
            "Epoch 108/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 18.0871 - acc: 0.9943 - val_loss: 22.1703 - val_acc: 0.9943\n",
            "Epoch 109/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 17.9979 - acc: 0.9944 - val_loss: 21.9605 - val_acc: 0.9944\n",
            "Epoch 110/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 18.0023 - acc: 0.9944 - val_loss: 21.9104 - val_acc: 0.9946\n",
            "Epoch 111/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 17.8525 - acc: 0.9944 - val_loss: 21.7194 - val_acc: 0.9944\n",
            "Epoch 112/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 17.8246 - acc: 0.9944 - val_loss: 21.7878 - val_acc: 0.9944\n",
            "Epoch 113/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 17.6750 - acc: 0.9944 - val_loss: 21.7258 - val_acc: 0.9944\n",
            "Epoch 114/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 17.7046 - acc: 0.9944 - val_loss: 21.7211 - val_acc: 0.9944\n",
            "Epoch 115/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 17.9212 - acc: 0.9944 - val_loss: 21.4904 - val_acc: 0.9945\n",
            "Epoch 116/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 17.5327 - acc: 0.9944 - val_loss: 22.1135 - val_acc: 0.9947\n",
            "Epoch 117/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 17.7594 - acc: 0.9944 - val_loss: 21.5375 - val_acc: 0.9944\n",
            "Epoch 118/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 17.5131 - acc: 0.9944 - val_loss: 21.7100 - val_acc: 0.9945\n",
            "Epoch 119/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 17.4277 - acc: 0.9944 - val_loss: 22.2676 - val_acc: 0.9943\n",
            "Epoch 120/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 17.4212 - acc: 0.9944 - val_loss: 21.3731 - val_acc: 0.9945\n",
            "Epoch 121/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 17.2761 - acc: 0.9944 - val_loss: 21.4455 - val_acc: 0.9946\n",
            "Epoch 122/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 17.1945 - acc: 0.9944 - val_loss: 22.1277 - val_acc: 0.9942\n",
            "Epoch 123/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 17.3317 - acc: 0.9944 - val_loss: 21.5634 - val_acc: 0.9943\n",
            "Epoch 124/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 17.1529 - acc: 0.9944 - val_loss: 21.4909 - val_acc: 0.9947\n",
            "Epoch 125/200\n",
            "2150/2150 [==============================] - 3s 1ms/step - loss: 17.0385 - acc: 0.9945 - val_loss: 21.5237 - val_acc: 0.9945\n",
            "Epoch 00125: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUObrj1shO8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "192d2e68-3621-4445-ff2a-221294203614"
      },
      "source": [
        "# evaluation\n",
        "\n",
        "n = 10  # for 10 random indices\n",
        "index = np.random.choice(x_test.shape[0], n, replace=False)\n",
        "\n",
        "x_eval = x_test[index]\n",
        "print(\"Number of samples to evaluate: \", len(x_eval))\n",
        "print(\"Samples to evaluate: \", index)\n",
        "\n",
        "#encoded_imgs = ae.eval_model(x_test)\n",
        "encoded_imgs = ae.eval_model(x_eval)\n",
        "decoded_imgs = ae.eval_model(encoded_imgs)\n",
        "\n",
        "plot_results(x_eval, decoded_imgs)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples to evaluate:  10\n",
            "Samples to evaluate:  [ 33 263 322 292 285 123 373 395 488 158]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAADjCAYAAADdR/IFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nACAh/g8EDe/cLUV+6AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5GSTXZikY9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}